{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"GOnDXr2DuKXU"},"source":["# 5 機械学習の基礎（教師あり学習）"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ddm76XUXuKXV"},"source":["5章からは、機械学習について解説していきます。機械学習は、何かしらの目的を達成するための知識や行動を、データを読み込ませることで機械に獲得させるための技術です。機械学習は大きく、教師あり学習、教師なし学習、強化学習に分けられ、5章では、教師あり学習の具体的手法について学びます。この章を通し、機械学習の考え方とモデル構築の基本作法を理解し、正しく実行できるようになりましょう。\n","\n","\n","ゴール：機械学習の体系と概要を学び、モデル構築や評価を正しく実行できるようになる"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XxwnkLAkuKXV"},"source":["- **[5.1 機械学習の全体像](#5.1-機械学習の全体像)**\n","    - [5.1.1 機械学習とは](#5.1.1-機械学習とは)\n","    - [5.1.2 教師あり学習](#5.1.2-教師あり学習)\n","    - [5.1.3 教師なし学習](#5.1.3-教師なし学習)\n","    - [5.1.4 強化学習](#5.1.4-強化学習)\n","    - [5.1.5 この章で使うライブラリのインポート](#5.1.5-この章で使うライブラリのインポート)\n","<br><br>\n","- **[5.2 重回帰](#5.2-重回帰)** \n","    - [5.2.1 自動車価格データの取り込み](#5.2.1-自動車価格データの取り込み)\n","    - [5.2.2 データの整理](#5.2.2-データの整理)\n","    - [5.2.3 モデル構築と評価](#5.2.3-モデル構築と評価)\n","    - [5.2.4 モデル構築とモデル評価の流れのまとめ](#5.2.4-モデル構築とモデル評価の流れのまとめ)\n","<br><br>\n","- **[5.3 ロジスティック回帰](#5.3-ロジスティック回帰)** \n","    - [5.3.1 ロジスティック回帰の例](#5.3.1-ロジスティック回帰の例)\n","    - [5.3.2 データの整理](#5.3.2-データの整理)\n","    - [5.3.3 モデル構築と評価](#5.3.3-モデル構築と評価)\n","    - [5.3.4 スケーリングによる予測精度の向上](#5.3.4-スケーリングによる予測精度の向上)\n","<br><br>\n","- **[5.4 正則化項のある回帰：ラッソ回帰、リッジ回帰](#5.4-正則化項のある回帰：ラッソ回帰、リッジ回帰)** \n","    - [5.4.1 ラッソ回帰、リッジ回帰の特徴](#5.4.1-ラッソ回帰、リッジ回帰の特徴)\n","    - [5.4.2 重回帰とリッジ回帰の比較](#5.4.2-重回帰とリッジ回帰の比較)\n","<br><br>\n","- **[5.5 決定木](#5.5-決定木)** \n","    - [5.5.1 キノコデータセット](#5.5.1-キノコデータセット)\n","    - [5.5.2 データの整理](#5.5.2-データの整理)\n","    - [5.5.3 エントロピー：不純度の指標](#5.5.3-エントロピー：不純度の指標)\n","    - [5.5.4 情報利得：分岐条件の有益さを測る](#5.5.4-情報利得：分岐条件の有益さを測る)\n","    - [5.5.5 決定木のモデル構築](#5.5.5-決定木のモデル構築)    \n","<br><br>\n","- **[5.6 k-NN（k近傍法）](#5.6-k-NN（k近傍法）)** \n","    - [5.6.1 k-NNのモデル構築](#5.6.1-k-NNのモデル構築)\n","<br><br>\n","- **[5.7 サポートベクターマシン](#5.7-サポートベクターマシン)** \n","    - [5.7.1 サポートベクターマシンのモデル構築](#5.7.1-サポートベクターマシンのモデル構築)\n","<br><br>\n","- **[5.8 総合問題](#5.8-総合問題)**\n","    - [■ 総合問題5-1 教師あり学習の用語（1）](#■-総合問題5-1-教師あり学習の用語（1）)\n","    - [■ 総合問題5-2 決定木](#■-総合問題5-2-決定木)\n","    - [■ 総合問題5-3 ノーフリーランチ](#■-総合問題5-3-ノーフリーランチ)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NlkqMla2uKXV"},"source":["## 5.1 機械学習の全体像\n","ゴール：機械学習の体系と教師あり学習、教師なし学習の概要を知る"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ubhOnmxquKXV"},"source":["この章では、教師あり学習の具体的手法について学びます。教師あり学習は、機械学習の中で最もビジネス活用が進んでいる技術です。この章を通し、機械学習の考え方とモデル構築の基本作法を理解し、正しく実行できるようになりましょう。\n","\n","教師あり学習の話に入る前に、教師なし学習なども含めて、まずは、機械学習の全体像を俯瞰してみましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ByFitDPguKXV"},"source":["### 5.1.1 機械学習とは\n","キーワード：機械学習、教師あり学習、教師なし学習、強化学習"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6NibPQuSuKXV"},"source":["**機械学習（machine learning）**は、何かしらの目的を達成するための知識や行動を、データを読み込ませることで機械に獲得させるための技術です。機械学習は大きく、**教師あり学習（supervised learning）**、**教師なし学習（unsupervised learning）**、**強化学習（reinforcement learning）**に分けられます。この分け方以外にも、教師あり学習と教師なし学習の2つに分けたり、これらの3つに、さらに半教師あり学習を加えて4つに分けることもあります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1yeVSoNHuKXV"},"source":["#### 教師あり学習と教師なし学習\n","\n","機械に読み込ませて知識や行動を獲得させるために使うデータのことを訓練データと言います。\n","教師あり学習と教師なし学習の違いは、訓練データに、目的変数や説明変数（後述）があるかどうかです。端的に言うと、正解のデータがあってそれを与えるのが教師あり学習、そうでないのが教師なし学習です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1zpvOiequKXV"},"source":["①教師あり学習\n","\n","説明変数（インプット）から目的変数（アウトプット）を予測するモデルを求める手法です。訓練データには目的変数や説明変数があり、あらかじめ作ったモデルに訓練データの説明変数を入力し、そのモデルからの出力が訓練データの目的変数に近づくようにモデルのパラメータを調整することで学習していきます。この章で詳しく説明します。\n","\n","たとえば、メールのタイトルや内容（説明変数）からスパムか否か（目的変数）を識別したい、株の売買状況（説明変数）から株価（目的変数）を予測したいときなどに使われます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"I18ofZTHuKXV"},"source":["②教師なし学習\n","\n","入力データそのものに着目し、データに潜むパターンや示唆を見いだす手法です。訓練データに目的変数や説明変数はありません。多数のデータをいくつかの類似グループに分けるクラスタリングや、データ次元（変数の数）を、元のデータの情報を失わないようにより少数の次元に縮約する主成分分析（PCA:Principal Component Analysis）などの手法があります。データに解釈を与える探索的分析やデータの次元圧縮（dimentional reduction）などに使われます。こちらは次の章で詳しく説明します。なお、次元圧縮は教師あり学習もありますが、次の章で扱うのは教師なし学習の次元圧縮です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RDnLakRTuKXV"},"source":["#### 強化学習\n","\n","強化学習は、プログラム（機械）の一連の行動の結果に対して報酬を与えることで、機械に実現させたい知識や行動ルールを獲得させようとする手法です。教師あり学習では1つ1つの行動に正解データを付与する必要がありますが、特に対戦相手のいるゲームなど相互作用的な環境下で行動ルールを獲得する必要がある場合、すべての局面に対して正解データを付与することは困難です。\n","\n","そのため、一連の行動の結果に基づく報酬によって行動ルールを獲得させようとする強化学習技術という手法は、教師あり学習では表現困難なケースを扱える学習方式として、近年注目を集めています。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1x3kK6KXuKXV"},"source":["#### 機械学習を適用するにあたって\n","\n","本書では、与えられたデータに対して機械学習を適用するところから始めますが、実際のデータ分析の現場においては、「基本統計量を取得する」「ヒストグラムや散布図を作成する」など、データの基本的な観察と理解を怠らないようにしましょう。データの品質は機械学習のアウトプットの品質にも大きな影響を与えるためです。また、そのような一連の確認作業からデータ上の有益な気付きを得られることもあります。機械学習を使うことを目的とせず、あくまで1つの手段であることを留意しておきましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TLS9b8fsuKXV"},"source":[">**[ポイント]**\n",">\n",">現場でデータ分析をするときは、機械学習を適応する前に、基本統計量や散布図を作成し、データの傾向や全体像を抑えましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pDBgCM7juKXV"},"source":["機械学習の入門者には「、参考文献集にある「Pythonでの機械学習に役立つ書籍」などが参考になるでしょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jF_W_yUwuKXV"},"source":["ビジネス的な視点で機械学習を活かすことを学ぶには、参考文献集にある「ビジネス視点で機械学習を活かすのに役立つ書籍」などが参考になります。\n","\n","また、1冊の専門書で機械学習のモデルや実装に関する情報をすべて記載するのは無理なので、何かわからないこと（パラメータの設定など）があった場合、大事になるのは公式ドキュメント\n","に戻ることです。公式ドキュメントはぎっしり書いてあってなかなか読み切れるものではないですが、モデルの細かなパラメータ等の説明がありますので、確実です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VXbXFLO-uKXV"},"source":[">**[ポイント]**\n",">\n",">機械学習等のモデルでパラメータやモデルの特性などわからないことがあれば、まずは公式ドキュメントを調べましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7CkiqLyVuKXV"},"source":["### 5.1.2 教師あり学習\n","キーワード：目的変数、説明変数、回帰、分類"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZZr6bzXIuKXV"},"source":["教師あり学習は、訓練データを与えて、そこに含まれる正解データを予測するためのモデルを構築する手法です。先に説明したとおり、訓練データの中で予測したい変数のことを**目的変数**（他には正解データ、応答変数、ターゲット変数、従属変数などとも呼ばれます）、目的変数を説明するための変数のことを**説明変数**と言います（他には特徴量、予測変数、独立変数などとも呼ばれます）。\n","\n","$y=f(x)$という関数があるとすると、$y$が目的変数、$x$が説明変数、関数$f(x)$がモデルです。たとえば、ある消費財ブランドの購買者が、将来ブランド非購買になるか否か（目的変数）を予測したいときは、過去のさまざまなデータ（顧客属性、購買頻度、関連ブランドの購入有無など）を説明変数として扱います。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"aMQSBZAtuKXV"},"source":["#### 教師あり学習の手法\n","\n","教師あり学習は目的変数のデータ形式によって、いくつかの種類に分類できます。目的変数が株価など数値を取る場合を**回帰(regression)**、「男性・女性」「幼児・小学生・学生・大人」などのカテゴリになる場合を**分類（classification）**といいます。たとえば先ほどのブランド非購買になるか否かのケースは、「購入する」か「購入しないか」の2つのカテゴリに分ける分類タスクです。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iRxRwnRDuKXV"},"source":["教師あり学習のアルゴリズム（手法）には、**重回帰（multiple linear regression）、ロジスティック回帰（logistic regression）、k近傍法（k-Nearest Neighbors）、決定木（Decision Tree）、サポートベクターマシン（Support Vector Machine）、ランダムフォレスト（Random Forest）、勾配ブースティング（Gradient Boosting）**等があります。これらの手法は、回帰で使われるときもあれば、分類で使われるときもあるので、注意しましょう。\n","\n","たとえば、ロジスティック回帰は回帰という名前がついていますが、分類の用途で使われます。決定木は一般的に分類に使う手法ですがこの場合は分類木といい、回帰の場合は回帰木といいます。後に個別に説明します。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VYFooP77uKXV"},"source":["どの手法を選択するのかは、求めるモデルの性能で決めるのが基本です。しかし学習結果の解釈性（interpretability/解釈しやすさ）を優先したい場合は重回帰、ロジスティック回帰、決定木などの比較的シンプルな手法を意図的に採用することもあります。サポートベクターマシンなどは説明がしにくく、非専門家が1回聞いてすぐに理解できる手法ではないためです（機械学習で「決定木」は理解しやすいという記載もありますが、非専門家にとっては必ずしもわかりやすい概念ではないことを留意しておきましょう）。解釈性を優先すべき局面なのか、解釈よりも精度を追求すべき局面なのかについては、ケースバイケースで判断するようにしましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DgfLavvtuKXV"},"source":["### 5.1.3 教師なし学習\n","キーワード：クラスタリング、主成分分析、マーケットバスケット分析"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XSTwLYrNuKXV"},"source":["教師なし学習は目的変数がなく入力データそのものに注目した学習で、データに潜むパターンや示唆を見出そうとするものです。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cpaMUhMPuKXV"},"source":["#### 教師なし学習の手法\n","\n","教師なし学習の代表的な手法が、多数のデータをいくつかの類似のグループに分ける**クラスタリング（clustering）**です。たとえば、ある消費者がどのような嗜好グループに分かれるかといったマーケティング分析などに使われます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3P3Gft0duKXV"},"source":["クラスタリングは、データそのものの特徴を探す手法であることから、探索的なデータ分析手法とも位置づけられます。クラスタリング結果に基づき対象データをグルーピングしたら終わりではなく、そこに解釈を与えそれがビジネスなどの現場感覚とズレていないかを確認することは重要です。探索的なデータ分析では完全な自動化は難しく、人の判断が重要な役割を担うことを留意しましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZTP09Au5uKXV"},"source":["教師なし学習にはほかにも、**主成分分析（Principal Component Analysis）**や**マーケットバスケット分析（Market Basket Analysis）**などがあります。主成分分析は、多数の変数をそれらの情報を失わないように縮約して、変数を減らす分析手法です。マーケットバスケット分析はPOS（Point of Sales）といわれる購買データ等の分析に使われ、ある商品Aを買っている人は高い確率である商品Bも買っている、といったアソシエーションルール（関連性の強い事象の組み合わせのこと）を求めてくれる分析手法です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xZsBAaqluKXV"},"source":["参考文献集にある「データマイニングが学べる書籍」に挙げている書籍では、教師あり学習を「目的志向的データマイニング」、教師なし学習を「探索的データマイニング」と大別しており、ビジネスの現場でどのように機械学習やデータマイニングが使われているかを学ぶことができます。ビジネス視点から本書の理解を更に深めたい方にはオススメです。なお、参考文献集「データマイニングが学べる書籍」のうち上2つは翻訳本で原書の一部分がカットされていますので、英語が読める方は原書が良いでしょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mZ2cMwI1uKXW"},"source":["### 5.1.4 強化学習\n","キーワード：動的計画法、モンテカルロ法、TD学習"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"P1axpEbvuKXW"},"source":["強化学習は、ある報酬を最大化するために何をすべきかの行動ルールを、機械に学習させるための技術です。報酬は機械の一連の行動の結果に対し目的と整合するように設計します。つまり望ましい結果には高い報酬を、望ましくない結果には低い報酬を与えるようにします。教師あり学習のように1つ1つの行動に対する正解データは与えられず、その代わりどのような行動を取ったら最終的により大きな報酬を得られるかを見つけ出そうとします。強化学習では、機械（エージェント）が存在する環境、および他のエージェントとの相互作用の中で学習が進みます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eRSJp4MYuKXW"},"source":["実例で言うとたとえば、「赤ちゃん（エージェント）は歩き方を教わっていないのに自分がおかれている環境の中から試行錯誤しながら歩けるようになる」「自動車（エージェント）が他の自動車（他のエージェント）と衝突することなく走行できるようになる」などが、強化学習の例となります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oE7pOl6kuKXW"},"source":["#### 強化学習の手法\n","\n","強化学習ではエージェントが探索的に行動し、環境との相互作用の中から学習が進むため、探索と知識利用のジレンマ（Exploration-Exploitation Dilemma）をどのように扱うかが重要なテーマです。これは、過去の行動から学んだ結果を踏まえて「一番良い行動」を取っていたら新しい行動を見つけられなくなるし（知識に偏る）、「もっと良い行動」を求めて新しい行動ばかりしていると過去の経験を活かせない（探索に偏る）ので、探索と知識利用のバランスをどうとるかが難しい、ということです。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"G5WTKSXRuKXW"},"source":["強化学習のアプローチには動的計画法、モンテカルロ法やTD学習などがあります。動的計画法は明示的な知識があることを前提としますが、モンテカルロ法は環境における完全な知識を必要とせず経験のみを必要とする方法です。なお本書では、強化学習については概念の紹介までとします。さらに学習を深めたい方は、上記までに登場した用語を参考に、参考文献集「強化学習を学べる書籍」や[OpenAIのサイト](https://gym.openai.com)などを参照して下さい。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1CFFg8yIuKXW"},"source":["### 5.1.5 この章で使うライブラリのインポート\n","\n","この章では、以前紹介した各種ライブラリのほか、機械学習ライブラリのScikit-learnを使います。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sNyP4rpruKXW"},"source":["Scikit-learnは、単回帰分析の際にも使いました。上記でも紹介しましたが、参考URL「B-27」のScikit-learnの公式ドキュメントには、詳細な仕様や使い方が記されているので、参考にしてください。Sciklt-learnのライブラリには、機械学習用のクラスだけでなくサンプルデータもいくつか含まれています。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5gKD6ZiBuKXW"},"source":["この章では、次のようにインポートしていることを前提として進めていきます。"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":835,"status":"ok","timestamp":1663935878879,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"YYJnE3y1uKXW","outputId":"09683d5c-e0c0-423e-b14e-0f0039490b0e"},"outputs":[{"data":{"text/plain":["'%.3f'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# データ加工・処理・分析ライブラリ\n","import sklearn\n","import numpy as np\n","import numpy.random as random\n","import scipy as sp\n","from pandas import Series, DataFrame\n","import pandas as pd\n","\n","# 可視化ライブラリ\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import seaborn as sns\n","%matplotlib inline\n","\n","# 機械学習ライブラリ\n","\n","# 小数第3位まで表示\n","%precision 3\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WJ8WLrXEuKXW"},"source":["## 5.2 重回帰\n","キーワード：目的変数、説明変数、多重共線性、変数選択法"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"C06c6-fnuKXW"},"source":["教師あり学習の1つ目として、まずは、**重回帰（multiple lienar regression**について学びます。以前扱った単回帰では目的変数に対して説明変数は1つでした。この考え方を拡張し、説明変数が1つではなく複数ある場合を扱うのが重回帰です。重回帰によって、各説明変数の係数（回帰係数）が推定され予測値を計算できます。回帰係数は予測値と目的変数の2乗誤差が最小になるように推定されます。以下が重回帰の図解です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WK0SrCeQuKXW"},"source":["\n","![](http://diary-ba.up.n.seesaa.net/diary-ba/image/E9878DE59B9EE5B8B0E5BC8FE383A2E38387E383AB.png?d=a1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cXwZvF7PuKXW"},"source":["参照URL:http://diary-ba.up.n.seesaa.net/diary-ba/image/E9878DE59B9EE5B8B0E5BC8FE383A2E38387E383AB.png?d=a1"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Z56iy1WsuKXX"},"source":["### 5.2.1 自動車価格データの取り込み\n","\n","それでは、実際にやってみましょう。ここでは、自動車の価格とそれらの属性（自動車の大きさなど）データがあるとき、その属性から自動車価格を予測するモデルを重回帰を使って構築してみます。\n","データは、次のURLで公開されているものを利用します。\n","\n","http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cg7FSKuquKXX"},"outputs":[],"source":["# インポート\n","import requests\n","import zipfile\n","import io\n","\n","# 自動車価格データを取得\n","url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'\n","res = requests.get(url).content\n","\n","# 取得したデータをDataFrameオブジェクトとして読み込み\n","auto = pd.read_csv(io.StringIO(res.decode('utf-8')), header=None)\n","\n","# データの列にラベルを設定\n","auto.columns = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors',\n","                'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height',\n","                'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', 'bore',\n","                'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"THFb-qGhuKXX"},"source":["上記のプログラムを実行すると、変数`auto`にPandasの`DataFrame`オブジェクトとして、自動車価格データが格納されます。\n","実際に、どのようなデータなのか確認してみましょう。"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1663935878883,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"R_OgFbGPuKXX","outputId":"8aa12e76-de75-48dc-e497-e02dce2cd81b"},"outputs":[{"name":"stdout","output_type":"stream","text":["自動車データの形式:(205, 26)\n"]}],"source":["print('自動車データの形式:{}'.format(auto.shape))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6TfaPA1fuKXX"},"source":["205行、26列のデータであることが分かります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Oy6_DMinuKXX"},"source":["続いて次のように`head()`メソッドで、最初の5行を表示してみます。"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1635295689301,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"uD-ZGkKUuKXX","outputId":"76a8acbd-0ecb-4c91-d984-8f3425180178","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>symboling</th>\n","      <th>normalized-losses</th>\n","      <th>make</th>\n","      <th>fuel-type</th>\n","      <th>aspiration</th>\n","      <th>num-of-doors</th>\n","      <th>body-style</th>\n","      <th>drive-wheels</th>\n","      <th>engine-location</th>\n","      <th>wheel-base</th>\n","      <th>...</th>\n","      <th>engine-size</th>\n","      <th>fuel-system</th>\n","      <th>bore</th>\n","      <th>stroke</th>\n","      <th>compression-ratio</th>\n","      <th>horsepower</th>\n","      <th>peak-rpm</th>\n","      <th>city-mpg</th>\n","      <th>highway-mpg</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>?</td>\n","      <td>alfa-romero</td>\n","      <td>gas</td>\n","      <td>std</td>\n","      <td>two</td>\n","      <td>convertible</td>\n","      <td>rwd</td>\n","      <td>front</td>\n","      <td>88.6</td>\n","      <td>...</td>\n","      <td>130</td>\n","      <td>mpfi</td>\n","      <td>3.47</td>\n","      <td>2.68</td>\n","      <td>9.0</td>\n","      <td>111</td>\n","      <td>5000</td>\n","      <td>21</td>\n","      <td>27</td>\n","      <td>13495</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>?</td>\n","      <td>alfa-romero</td>\n","      <td>gas</td>\n","      <td>std</td>\n","      <td>two</td>\n","      <td>convertible</td>\n","      <td>rwd</td>\n","      <td>front</td>\n","      <td>88.6</td>\n","      <td>...</td>\n","      <td>130</td>\n","      <td>mpfi</td>\n","      <td>3.47</td>\n","      <td>2.68</td>\n","      <td>9.0</td>\n","      <td>111</td>\n","      <td>5000</td>\n","      <td>21</td>\n","      <td>27</td>\n","      <td>16500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>?</td>\n","      <td>alfa-romero</td>\n","      <td>gas</td>\n","      <td>std</td>\n","      <td>two</td>\n","      <td>hatchback</td>\n","      <td>rwd</td>\n","      <td>front</td>\n","      <td>94.5</td>\n","      <td>...</td>\n","      <td>152</td>\n","      <td>mpfi</td>\n","      <td>2.68</td>\n","      <td>3.47</td>\n","      <td>9.0</td>\n","      <td>154</td>\n","      <td>5000</td>\n","      <td>19</td>\n","      <td>26</td>\n","      <td>16500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>164</td>\n","      <td>audi</td>\n","      <td>gas</td>\n","      <td>std</td>\n","      <td>four</td>\n","      <td>sedan</td>\n","      <td>fwd</td>\n","      <td>front</td>\n","      <td>99.8</td>\n","      <td>...</td>\n","      <td>109</td>\n","      <td>mpfi</td>\n","      <td>3.19</td>\n","      <td>3.40</td>\n","      <td>10.0</td>\n","      <td>102</td>\n","      <td>5500</td>\n","      <td>24</td>\n","      <td>30</td>\n","      <td>13950</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>164</td>\n","      <td>audi</td>\n","      <td>gas</td>\n","      <td>std</td>\n","      <td>four</td>\n","      <td>sedan</td>\n","      <td>4wd</td>\n","      <td>front</td>\n","      <td>99.4</td>\n","      <td>...</td>\n","      <td>136</td>\n","      <td>mpfi</td>\n","      <td>3.19</td>\n","      <td>3.40</td>\n","      <td>8.0</td>\n","      <td>115</td>\n","      <td>5500</td>\n","      <td>18</td>\n","      <td>22</td>\n","      <td>17450</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>"],"text/plain":["   symboling normalized-losses         make fuel-type aspiration num-of-doors   \n","0          3                 ?  alfa-romero       gas        std          two  \\\n","1          3                 ?  alfa-romero       gas        std          two   \n","2          1                 ?  alfa-romero       gas        std          two   \n","3          2               164         audi       gas        std         four   \n","4          2               164         audi       gas        std         four   \n","\n","    body-style drive-wheels engine-location  wheel-base  ...  engine-size   \n","0  convertible          rwd           front        88.6  ...          130  \\\n","1  convertible          rwd           front        88.6  ...          130   \n","2    hatchback          rwd           front        94.5  ...          152   \n","3        sedan          fwd           front        99.8  ...          109   \n","4        sedan          4wd           front        99.4  ...          136   \n","\n","   fuel-system  bore  stroke compression-ratio horsepower  peak-rpm city-mpg   \n","0         mpfi  3.47    2.68               9.0        111      5000       21  \\\n","1         mpfi  3.47    2.68               9.0        111      5000       21   \n","2         mpfi  2.68    3.47               9.0        154      5000       19   \n","3         mpfi  3.19    3.40              10.0        102      5500       24   \n","4         mpfi  3.19    3.40               8.0        115      5500       18   \n","\n","  highway-mpg  price  \n","0          27  13495  \n","1          27  16500  \n","2          26  16500  \n","3          30  13950  \n","4          22  17450  \n","\n","[5 rows x 26 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["auto.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FXBZEYzcuKXX"},"source":["このデータにおいて、自動車の価格は`price`に設定されています。ここでは自動車の属性から価格を予測するモデルを作ろうとしているのですから、`price`以外の値から`price`を予測するモデルを作るというのが課題となります。\n","\n","すべての説明変数から`price`を予測するのは複雑なので、この課題では、`horsepower`、`width`、`height`の3つの説明変数だけを使うものとします。つまり、`horsepower`、`width`、`height`という説明変数から`price`という目的変数を予測するというモデルを作成していくものとします。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jDv1iUFUuKXX"},"source":["### 5.2.2 データの整理\n","\n","入力データには不適切なものが含まれていることがあります。そこでまずは、データの内容を確認して適切なデータとして整理します。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JJltHcgXuKXX"},"source":["#### 不適切なデータの除去\n","\n","先ほど`head()`を使ってデータを確認しましたが、このとき、データの中に'?'があることに気づきます。多くの機械学習のアルゴリズムは、数値型データしか扱えないため、このような「?」などの非数値データを含む変数に対しては、それを取り除く前処理が必要です。\n","\n","今回の目的は`horsepower`、`width`、`height`から`price`を予測することなので、これらの変数に'?'データがあれば削除します。具体的には、'?'データを欠損値に変換をした上で欠損値を含む行を除外します。扱おうとしている`horsepower`、`width`、`height`、`price`の4つ変数に'?'データが、どれだけ含まれているのかは、次のプログラムで確認できます。"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1635295689301,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"mARVqvQHuKXX","outputId":"eae711ac-db4e-4849-d604-f090b3048da3"},"outputs":[{"data":{"text/plain":["price         4\n","horsepower    2\n","width         0\n","height        0\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# それぞれのカラムに ? が何個あるかカウント\n","auto = auto[['price', 'horsepower', 'width', 'height']]\n","auto.isin(['?']).sum()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"e5ahextwuKXX"},"source":["`price`と`horsepower`に'?'データが混入していることがわかるので、以前学んだPandasのテクニックを使って除外します。次のようにすると'?'がある行が除去されます。実行すると、行数が減っていることが確認できます。"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1635295689302,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"fy8GBBVNuKXX","outputId":"bd80d487-fdeb-4deb-aadf-b1537c390df5"},"outputs":[{"name":"stdout","output_type":"stream","text":["自動車データの形式:(199, 4)\n"]}],"source":["# '?'をNaNに置換して、NaNがある行を削除\n","auto = auto.replace('?', np.nan).dropna()\n","print('自動車データの形式:{}'.format(auto.shape))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1WGQpMJouKXX"},"source":["#### 型の変換\n","ここでデータの型を確認しておきましょう。次のようにして確認します。"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1635295689302,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"kO2ZMAfMuKXX","outputId":"17ebe602-f244-49a3-e134-f68c36c1e96d"},"outputs":[{"name":"stdout","output_type":"stream","text":["データ型の確認（型変換前）\n","price          object\n","horsepower     object\n","width         float64\n","height        float64\n","dtype: object\n","\n"]}],"source":["print('データ型の確認（型変換前）\\n{}\\n'.format(auto.dtypes))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yRXFjaLMuKXX"},"source":["確認すると`price`と`horsepower`が数値型ではないことがわかります。そこで`to_numeric`を使って数値型に変換しておきます。"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1635295689302,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"H5opVyS0uKXX","outputId":"5b883cda-b50a-495f-c99f-c7710a7f9d79"},"outputs":[{"name":"stdout","output_type":"stream","text":["データ型の確認（型変換後）\n","price           int64\n","horsepower      int64\n","width         float64\n","height        float64\n","dtype: object\n"]}],"source":["auto = auto.assign(price=pd.to_numeric(auto.price))\n","auto = auto.assign(horsepower=pd.to_numeric(auto.horsepower))\n","print('データ型の確認（型変換後）\\n{}'.format(auto.dtypes))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"O-q5m3GKuKXX"},"source":["#### 相関の確認\n","\n","以上の操作で、説明変数、目的変数のすべての行は、欠損が無くかつ数値型のデータ形式に加工されました。\n","続けて各変数の相関を確認します。次のように`corr()`を使うと、相関を確認できます。"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1635295689303,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"ai2aQmF_uKXX","outputId":"6e8b0098-9118-4a24-cdec-a0d2e3ab32a4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>price</th>\n","      <th>horsepower</th>\n","      <th>width</th>\n","      <th>height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>price</th>\n","      <td>1.000000</td>\n","      <td>0.810533</td>\n","      <td>0.753871</td>\n","      <td>0.134990</td>\n","    </tr>\n","    <tr>\n","      <th>horsepower</th>\n","      <td>0.810533</td>\n","      <td>1.000000</td>\n","      <td>0.615315</td>\n","      <td>-0.087407</td>\n","    </tr>\n","    <tr>\n","      <th>width</th>\n","      <td>0.753871</td>\n","      <td>0.615315</td>\n","      <td>1.000000</td>\n","      <td>0.309223</td>\n","    </tr>\n","    <tr>\n","      <th>height</th>\n","      <td>0.134990</td>\n","      <td>-0.087407</td>\n","      <td>0.309223</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               price  horsepower     width    height\n","price       1.000000    0.810533  0.753871  0.134990\n","horsepower  0.810533    1.000000  0.615315 -0.087407\n","width       0.753871    0.615315  1.000000  0.309223\n","height      0.134990   -0.087407  0.309223  1.000000"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["auto.corr()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jRTJ-c-guKXX"},"source":["`price`が今回の目的変数なので、それ以外の3変数に注目をすると、`width`と`horsepower`の相関が0.6程度と、やや高いことに気づきます。なぜこのような確認をしているかというと、相関の高い変数を同時に重回帰の説明変数とすると、**多重共線性（multi-collinearity）**が生じる可能性があるからです。\n","\n","\n","多重共線性とは変数間の高い相関のために回帰係数の分散が大きくなり、係数の有意性が失われてしまう現象です。このような現象を回避すべく、通常、重回帰のモデル構築においては、相関の高い変数群からは代表となる変数だけをモデルに使用します。しかしここでは実験なのでそこまで厳密に考えず、`width`と`horsepower`の両方を、`height`と一緒に残してモデル構築を進めることとします。\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MlwDf1R_uKXX"},"source":["### 5.2.3 モデル構築と評価\n","\n","データが揃ったのでモデルを構築してみましょう。重回帰のモデルを作り、その性能を調べるプログラムは下記のようになります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XPDw6be5uKXX"},"source":["下記のプログラムでは、説明変数を$X$、目的変数を$y$に設定しています。\n","\n","機械学習のモデル構築では、「モデル構築に使用する訓練データ」を使って学習させてモデルを構築し、そのモデルに訓練データとは別の「テストデータ」を入れて、そのテストデータに対して、どの程度の精度が得られるのかを確認することで性能を調べるのが一般的です。そこで以下では、Scikit-learnの`model_selection`モジュールの`train_test_split`関数を使い、訓練データとテストデータに分けています。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VlRC7NRZuKXX"},"source":["この関数はデータをランダムに2つに分ける関数です。どのような割合で分類するのかは`test_size`で決めます。ここでは`test_size`を0.5にしているので半分ずつに分かれます（たとえば、0.4にすると4対6に分けることもできます）。\n","\n","`ramdom_state`はランダムの度合いを設定するものです。ここでは`random_state`を0に設定しています。このように`random_state`を固定する（この場合は0に設定する）とランダム性がなくなり、何度実行しても、同じように分離されます。もし0でないと、実行のたびに、ある行が訓練データに分類されたりテストデータに分類されたりとまちまちになるので、結果が一定となりません。ですから実務では、`random_state`を固定して再現性を持たせることは、とても重要です。\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LNVOS-myuKXX"},"source":["重回帰のモデル構築は、`LinearRegression`クラスを使って行います。「`model = LinearRegression()`」でインスタンスを作成して、訓練データを「`model.fit(X_train, y_train)`」のように読み込ませると学習が完了します。学習したら、決定係数や回帰係数、切片を確認できます。決定係数とは、目的変数によって予測された値が、実際の目的変数の値とどのくらい近いかを示す値です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sIfWwn7vuKXX"},"source":["機械学習の目的は高い汎化性能の獲得（構築したモデルによって、未知データでも適切に予測できること）ですから、訓練データへのあてはまりを追求すれば良いモデルになりそうですが、実際はそうではなく、訓練データに対する精度は良いがテストデータに対する精度が低くなるということがしばしば起きます。このことを**過学習（overfitting）**もしくは**過剰学習**と呼び、モデル構築の段階において過学習になっていないかを検証します。詳しくは、後の章で学びます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"psLDOwVWxH5f"},"source":["重回帰分析の目的関数では、$y$を実測値、$ f(\\textbf{x}) = w_1x_1 + w_2x_2 + w_3x_3 +\\cdots + b $を予測値として、以下の式のように表されます。この式を最小化するような係数を求めます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y2EFSwe-zVjr"},"source":["\\begin{eqnarray}\n","\\sum^n_{i=1}(y_i-f(\\textbf{x}_i))^2\n","\\end{eqnarray}"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1635295689582,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"AoBdTFtHuKXX","outputId":"41a69ca0-e212-4931-dd92-72a4cb6f4a7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["決定係数(train):0.733\n","決定係数(test):0.737\n","\n","回帰係数\n","horsepower      81.651078\n","width         1829.174506\n","height         229.510077\n","dtype: float64\n","切片: -128409.046\n"]}],"source":["# データ分割（訓練データとテストデータ）のためのインポート\n","from sklearn.model_selection import train_test_split\n","\n","# 重回帰のモデル構築のためのインポート\n","from sklearn.linear_model import LinearRegression\n","\n"," # 目的変数にpriceを指定、説明変数にそれ以外を指定\n","X = auto.drop('price', axis=1)\n","y = auto['price']\n","\n","# 訓練データとテストデータに分ける\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n","\n","# 重回帰クラスの初期化と学習\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# 決定係数を表示\n","print('決定係数(train):{:.3f}'.format(model.score(X_train, y_train)))\n","print('決定係数(test):{:.3f}'.format(model.score(X_test, y_test)))\n"," \n","# 回帰係数と切片を表示\n","print('\\n回帰係数\\n{}'.format(pd.Series(model.coef_, index=X.columns)))\n","print('切片: {:.3f}'.format(model.intercept_))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lxJM38T6uKXY"},"source":["決定係数は`score`メソッドで取得できます。上記の結果では、`train`（訓練データ）で0.733、`test`（テストデータ）で0.737とわかります。訓練時スコアとテスト時のスコアが近いことから、このモデルは過学習に陥ってはいないと判断できます。\n","\n","### 5.2.4 モデル構築とモデル評価の流れのまとめ\n","\n","以上が重回帰によるモデル構築とモデル評価の流れです。以下で学ぶ決定木やSVMなども基本的に同じ流れで実行していきます。つまり、以下の流れがモデル構築とモデル評価の基本であることを押さえましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eSklMkXBuKXY"},"source":["- 各種モデル構築のためのクラスの初期化：`model = LinearRegression()`\n","- データを説明変数と目的変数に分ける：$X$と$y$\n","- 訓練データとテストデータに分ける：`train_test_split(X, y, test_size=0.5, random_state=0)`\n","- 訓練データによるあてはめ（学習）：`model.fit(X_train, y_train)`\n","- モデルの汎化性能をテストデータで確かめる：`model.score(X_test, y_test)`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VdEXPAiZuKXY"},"source":["ここでは、モデル構築の際、使用する説明変数として`horsepower`、`width`、`height`の3つを恣意的に選択しましたが、統計的に選択する方法もいくつかあります。具体的には、**変数増加法（前進的選択法）**、**変数減少法（後退的選択法）**、**ステップワイズ法**などで、選択するための規準も、RMSE（Root Mean Squared Error）、赤池情報量規準（AIC）、ベイズ情報量規準（BIC）などがあります。これらも絶対的にこの方法が有効というものではなく、モデルの汎化性能であったりビジネスドメイン知識なども考慮され選択されます。上記方法についての詳細は本書では割愛しますので、さらに学習を深めたい方は調べてみてください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4YBUDWTSuKXY"},"source":[">**[やってみよう]**\n",">\n",">変数増加法、変数減少法、ステップワイズ法について調べてみましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vYP8RTTRuKXY"},"source":["####  <練習問題 5-1>\n","本編で利用した自動車価格データを利用します。\n","このデータに対して、目的変数を`price`とし、説明変数に`length`と`engine-size`を使って重回帰のモデル構築をしてみましょう。このとき`train_test_split`を使って訓練データとテストデータが半分になるように分けてモデルを構築し、テストデータを使って、モデルのスコアを求めてください。`train_test_split`を実行する際には、`random_state`オプションを0に設定してください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bKpd3ShYuKXY"},"source":["####  <練習問題 5-2>\n","<練習問題 5-1>のデータに対して、目的変数は同じ`price`で、上記とは別の説明変数を使って重回帰のモデル構築をしてみましょう。ただし、訓練データとテストデータが半分になるように分けて学習して、テストデータでスコアを求めてください。なお、訓練データとテストデータに分ける関数の`random_state`は0に設定して実施してください。モデルの結果がどのように変わったでしょうか。またその原因を考察してみましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"w2wdEg_ZuKXY"},"source":["## 5.3 ロジスティック回帰\n","キーワード：ロジスティック回帰、交差エントロピー誤差関数、オッズ比"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rIr6r9S9uKXY"},"source":["前述のとおり、重回帰モデルは説明変数が複数ある回帰モデルで、目的変数は数値でした。このような変数を数値変数と言います。\n","\n","本節で学ぶ**ロジスティック回帰（logistic regression）**は目的変数が数値ではなく、たとえば、ある商品を買うか買わないか、ある会社が倒産するかしないかといった、カテゴリのデータを扱うアルゴリズムです。このようにカテゴリの形になっている変数をカテゴリ変数と言います。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"G2tfOpcTuKXY"},"source":["データサンプルが、あるカテゴリに属するかどうかの確率を計算するタスクを分類（classification）といい、そのためのアルゴリズムの1つがロジスティック回帰です。\n","\n","回帰という名前がついていますが、分類を扱うアルゴリズムですので注意しましょう（また、2分類だけではなく3分類以上についても使えます）。目的変数が数値の時と違い、分類タスクでは以下の目的関数が最小になるように学習します。この目的関数を**交差エントロピー誤差関数（cross-entropy error function）**と言い、正解カテゴリを予測できる確率が高くなるほど値が小さくなります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Q3f8VYJ9uKXY"},"source":["\\begin{eqnarray}\n","-\\sum^n_{i=1}[y_ilog(f(x_i))+(1-y_i)log(1-f(x_i))]\n","\\end{eqnarray}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Pmh0NkA2uKXY"},"source":["### 5.3.1 ロジスティック回帰の例\n","\n","それでは具体的にロジスティック回帰の例を見ていきましょう。ここでは、年齢や性別、職業などの個人に関するデータから、その人の収入が50K（5万ドル）を超えるかどうかを予測するためのモデルを構築してみましょう。元となるデータは、次のURLで取得できるものとします。\n","\n","http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n","\n","まずは次のようにデータを取得し、カラム名を設定します。データは32561行15例で構成されており、欠損値はありません。`head()`を使ってデータの先頭を見ると、`wrokclass`や`education`などのカテゴリ変数と`age`や`education_num`などの数値変数が混在したデータセットであるとわかります。"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1218,"status":"ok","timestamp":1635295690797,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"yiOS9dBuuKXY","outputId":"e95631aa-d4c6-4d54-ea9c-93d89265f147"},"outputs":[{"name":"stdout","output_type":"stream","text":["データの形式:(32561, 15)\n","欠損の数:0\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>flg-50K</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age          workclass  fnlwgt   education  education-num   \n","0   39          State-gov   77516   Bachelors             13  \\\n","1   50   Self-emp-not-inc   83311   Bachelors             13   \n","2   38            Private  215646     HS-grad              9   \n","3   53            Private  234721        11th              7   \n","4   28            Private  338409   Bachelors             13   \n","\n","        marital-status          occupation    relationship    race      sex   \n","0        Never-married        Adm-clerical   Not-in-family   White     Male  \\\n","1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n","2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n","3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n","4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n","\n","   capital-gain  capital-loss  hours-per-week  native-country flg-50K  \n","0          2174             0              40   United-States   <=50K  \n","1             0             0              13   United-States   <=50K  \n","2             0             0              40   United-States   <=50K  \n","3             0             0              40   United-States   <=50K  \n","4             0             0              40            Cuba   <=50K  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# データを取得\n","url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n","res = requests.get(url).content\n","\n","# 取得したデータをDataFrameオブジェクトとして読み込み\n","adult = pd.read_csv(io.StringIO(res.decode('utf-8')), header=None)\n","\n","# データの列にラベルを設定\n","adult.columns =['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n","                             'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n","                             'native-country', 'flg-50K']\n","\n","\n","# データの形式と欠損数を出力\n","print('データの形式:{}'.format(adult.shape))\n","print('欠損の数:{}'.format(adult.isnull().sum().sum()))\n","\n","# データの先頭5行を出力\n","adult.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YGtfLrE1uKXY"},"source":["### 5.3.2 データの整理\n","\n","このデータセットにおいて、収入が50Kを超えるかどうかを示す目的変数は`flg-50K`です。データの値は「`<=50K`」と「`>50K`」で、このままでは扱いにくいので、0または1のフラグが入った変数に変換します。まずは、「`<=50K`」と「`>50K`」の行が、それぞれいくつあるかを確認してみます。"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1635295690797,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"yQsg_sPMuKXY","outputId":"f9bc03df-6f2a-4af5-90b9-cfd216933e84"},"outputs":[{"data":{"text/plain":["flg-50K\n"," <=50K    24720\n"," >50K      7841\n","dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["adult.groupby('flg-50K').size()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qVCgqH_uuKXY"},"source":["「`<=50K`」が24,720行、「`>50K`」が7,841行であることが分かります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"L6jJqwjnuKXY"},"source":["次に、「fin_flg」というカラムを追加して、「`>50K`」である行には1、それ以外は0とフラグ立てをします。フラグ立てには`lambda`や`map`を使います。変換したら、念のため上の集計結果と同じであることをチェックします。"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1635295690798,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"eNR9aFeHuKXY","outputId":"5e6f0b15-9c71-4ab3-8efa-e65b0a97644a"},"outputs":[{"data":{"text/plain":["fin_flg\n","0    24720\n","1     7841\n","dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# 「fin_flg」カラムを追加し、もし「flg-50K」カラムの値が「>50K」だったら1、そうでなければ0をセットする\n","adult['fin_flg'] = adult['flg-50K'].map(lambda x: 1 if x == ' >50K' else 0)\n","adult.groupby('fin_flg').size()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sJ8Zq777uKXY"},"source":["「`<=50K`」と「`>50K`」の行数が、「0」と「1」の行数と一致したのでうまくいったことが分かります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wU_McStOuKXY"},"source":["### 5.3.3 モデル構築と評価\n","いよいよロジスティク回帰のモデル構築です。説明変数として、数値変数の`age`、`fnlwgt`、`education-num`、`capital-gain`、`capital-loss`を使うことにします。目的変数は、先ほど「1」と「0」のフラグを立てた`fin_flg`です。\n","\n","ロジスティック回帰のモデル構築には`LogisticRegression`クラスを使います。訓練データとテストデータに分けたり、`score`メソッドで評価したりする方法は、重回帰のときと同じです。"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":469,"status":"ok","timestamp":1635295691260,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"1P6kZpEGuKXY","outputId":"8f250f97-c162-42d7-bf24-9e6bef021628"},"outputs":[{"name":"stdout","output_type":"stream","text":["正解率(train):0.797\n","正解率(test):0.798\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","\n","# 説明変数と目的変数の設定\n","X = adult[['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss']]\n","y = adult['fin_flg']\n","\n","# 訓練データとテストデータに分ける\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n","\n","# ロジスティック回帰クラスの初期化と学習\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","print('正解率(train):{:.3f}'.format(model.score(X_train, y_train)))\n","print('正解率(test):{:.3f}'.format(model.score(X_test, y_test)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"575MBO0uuKXY"},"source":["上記の結果から、訓練データとテストデータともに約80%の正解率であり、過学習は起きていないと判断できます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CQIJ6EzAuKXY"},"source":["学習済みモデルの各変数（age、fnlwgt、education-num、capital-gain、capital-loss）の係数を、`coef_`属性を取得することで確認してみます。"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1635295691260,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"5vUuHCjAuKXY","outputId":"858d9216-a472-4d0a-b1df-6efa47935864"},"outputs":[{"data":{"text/plain":["array([[-1.185e-02, -4.379e-06, -2.774e-03,  3.274e-04,  7.532e-04]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["model.coef_"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nKiVYw75uKXY"},"source":["また、それぞれのオッズ比は以下のように算出できます。オッズ比とは、それぞれの係数が1増加したとき、正解率にどの程度影響があるかを示す指標です。"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1635295691261,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"36mUceT4uKXY","outputId":"62014c07-c35a-4856-d7c2-b85d5ced494e"},"outputs":[{"data":{"text/plain":["array([[0.988, 1.   , 0.997, 1.   , 1.001]])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["np.exp(model.coef_)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"b_9qvG9_uKXY"},"source":["### 5.3.4 スケーリングによる予測精度の向上\n","\n","ここで予測精度を上げるためのアプローチの1つであるスケーリングについて紹介します。このモデルでは`age`、`fnlwgt`、`education-num`、`capital-gain`、`capital-los`の5つの説明変数を使っていますが、それぞれの単位や大きさは異なっています。このままだとモデルの学習が値の大きな変数に引っ張られ、値の小さな変数の影響が小さくなる懸念があります。\n","\n","そこで、それを防ぐため、説明変数の標準化を実施します。標準化とはスケーリングの一種で、データの各値から変数列の平均を引き、標準偏差で割ります。こうすることで変数間の単位が消え、数値の大小と意味するところが合致します（値が0ならそれは平均値、1なら1標準偏差だけ平均値より大きい値とわかります）。データを標準化するには`StandardScaler`クラスを使います。"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1635295691261,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"ejpBBf-3uKXY","outputId":"fe074094-2801-4b3e-8b70-e9aa6d3aed2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["正解率(train):0.811\n","正解率(test):0.810\n"]}],"source":["# 標準化のためのクラスをインポート\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","# Xとyを設定\n","X = adult[['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss']]\n","y = adult['fin_flg']\n","\n","# 訓練データとテストデータに分ける\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n","\n","# 標準化処理\n","sc = StandardScaler()\n","sc.fit(X_train)\n","X_train_std = sc.transform(X_train)\n","X_test_std = sc.transform(X_test)\n","\n","# ロジスティック回帰クラスの初期化と学習\n","model = LogisticRegression()\n","model.fit(X_train_std, y_train)\n","\n","# 正解率の表示\n","print('正解率(train):{:.3f}'.format(model.score(X_train_std, y_train)))\n","print('正解率(test):{:.3f}'.format(model.score(X_test_std, y_test)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kDg7X_lvuKXZ"},"source":["上記の結果を見るとわかるように、標準化しない場合に比べて正解率が上昇しています。このように説明変数の尺度を揃えることで、機械学習のアルゴリズムをよりうまく動作させられます。標準化処理で留意しておきたいポイントは、訓練データにだけ平均と標準偏差を使用している点です。テスト用データは将来手に入るであろう未知データという位置づけですから、そのデータを使ってモデルを評価することはできません。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5OeD2o21uKXZ"},"source":["####  <練習問題 5-3>\n","`sklearn.datasets`モジュールの`load_breast_cancer`関数を使って乳がんデータを読み込んで、目的変数を`cancer.target`として、`cancer.data`を説明変数にロジスティック回帰で予測モデルを構築してください。この時、訓練データとテストデータに分ける`train_test_split（random_state=0）`を使って、テストデータにおけるスコアを求めてください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"C_NRh4jDuKXZ"},"source":["####  <練習問題 5-4>\n","<練習問題 5-3>と同じ設定で、同じデータに対して、特徴量を標準化してモデル構築してみてください。その上で、上記の結果と比較してください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6lE9kOC5uKXZ"},"source":["## 5.4 正則化項のある回帰：ラッソ回帰、リッジ回帰\n","キーワード：正則化、ラッソ回帰、リッジ回帰"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JNU0rbpXuKXZ"},"source":["次にラッソ回帰とリッジ回帰を説明します。これらは入力が少し動いたときに出力が大きく変化する場面において、重回帰のモデルにおいて過学習が起こりにくいという特徴があります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NxUO7PA4uKXZ"},"source":["\n","### 5.4.1 ラッソ回帰、リッジ回帰の特徴\n","\n","重回帰では、予測値と目的変数の2乗誤差を最小にするように回帰係数を推定します。それに対して、ラッソ回帰やリッジ回帰には、2乗誤差を小さくしようとする以外に、回帰係数自体が大きくなることを避ける仕掛けがあります。一般的に、回帰係数が大きいモデルはインプットの少しの動きでアウトプットが大きく動くようになります。つまり、入出力関係が複雑なモデルになります。このような複雑なモデルは、訓練データには当てはまるが未知のデータには当てはまらない、過学習を引き起こすリスクが高まります。そこで回帰係数を推定する際、モデルの複雑さを表す項を損失関数（loss function）に追加し、それを含め誤差を最小化するように回帰係数を推定しようとしたものがラッソ回帰、およびリッジ回帰なのです。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lOmx72pZuKXZ"},"source":["具体的には、ラッソ回帰やリッジ回帰では、回帰係数を推定する際の損失関数を以下のように定義します。このときの第二項を正則化項と言います。$q=1$の時はラッソ回帰、$q=2$の時はリッジ回帰と呼びます（$M$：変数の数、$w$：重み付けまたは係数、$λ$：正則化パラメータ）。正則化項はモデルの複雑さを抑える役割を持った項です。**正則化（regularization）**とは、より一般的に、モデルの複雑さを低減するための工夫全般を指す用語です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eItSmLomuKXZ"},"source":["\\begin{eqnarray}\n","\\sum^n_{i=1}(y_i-f(x_i))^2+\\lambda\\sum^M_{j=1} |w_{j}|^q\n","\\end{eqnarray}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3eRdWPs0uKXZ"},"source":["この式の定義から、変数の数$M$を増やせば増やすほど、重みも増やせば増やすほど第二項の損失関数の値が大きくなり、それがペナルティとなることがわかると思います。重回帰やロジスティック回帰が、投入する説明変数の数を分析者側で調整することによってモデルの複雑性を調整するのに対し、ラッソ回帰、リッジ回帰はパラメータ自体の大きさをモデル自身が小さく抑えることによってモデルの複雑性を調整してくれます。訓練スコアとテストスコアに乖離がある場合、正則化項のあるアルゴリズムを使用することで汎化性能を改善できる可能性があるということです。ちなみに、Scikit-learnのロジスティック回帰はデフォルトでq=2の正則化項が損失関数に含まれていますが、従来のモデル名と別の名前は付けられていません。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"om2NWMOtuKXZ"},"source":["### 5.4.2 重回帰とリッジ回帰の比較\n","\n","先程の重回帰で使った自動車価格のデータ（`auto`）を使ってリッジ回帰モデルを作り、重回帰とリッジ回帰の結果の差を確認してみましょう。ここで使うデータの先頭5行を表示してみます。"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1635295691262,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"F8CaQWGZuKXZ","outputId":"1434a350-197e-41ba-e118-2dfbe2964263"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>price</th>\n","      <th>horsepower</th>\n","      <th>width</th>\n","      <th>height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13495</td>\n","      <td>111</td>\n","      <td>64.1</td>\n","      <td>48.8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>16500</td>\n","      <td>111</td>\n","      <td>64.1</td>\n","      <td>48.8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>16500</td>\n","      <td>154</td>\n","      <td>65.5</td>\n","      <td>52.4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13950</td>\n","      <td>102</td>\n","      <td>66.2</td>\n","      <td>54.3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17450</td>\n","      <td>115</td>\n","      <td>66.4</td>\n","      <td>54.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   price  horsepower  width  height\n","0  13495         111   64.1    48.8\n","1  16500         111   64.1    48.8\n","2  16500         154   65.5    52.4\n","3  13950         102   66.2    54.3\n","4  17450         115   66.4    54.3"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["auto.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QWUjvk5duKXZ"},"source":["`sklearn.linear_model`モジュールの`Ridge`クラスを使うと、リッジ回帰モデルを構築できます。次のプログラムは、`LinearRegression`クラスを使った重回帰モデル（`linear`）と`Ridge`クラスを使ったリッジ回帰モデル（`ridge`）を作り、その結果を比較するものです。"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1635295691609,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"gQlP9cFVuKXZ","outputId":"fa09f3fa-e86b-44f8-80ce-b884959e72b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["LinearRegression(train):0.733358\n","LinearRegression(test):0.737069\n","Ridge(train):0.733355\n","Ridge(test):0.737768\n"]}],"source":["# リッジ回帰用のクラス\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import train_test_split\n","\n","# 訓練データとテストデータに分割\n","X = auto.drop('price', axis=1)\n","y = auto['price']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n","\n","# モデルの構築と評価\n","linear = LinearRegression()\n","ridge = Ridge(random_state=0)\n","\n","for model in [linear, ridge]:\n","    model.fit(X_train, y_train)\n","    print('{}(train):{:.6f}'.format(model.__class__.__name__ , model.score(X_train, y_train)))\n","    print('{}(test):{:.6f}'.format(model.__class__.__name__ , model.score(X_test, y_test)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZQaENA2VuKXZ"},"source":["どちらも性能は極めて近いですが、傾向として、訓練データにおいては重回帰の正解率が高く、テストデータにおいてそれが逆転しているのは、正則化項による効果と推察されます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MlZTWUCcuKXZ"},"source":["####  <練習問題 5-5>\n","\n","<練習問題 5-1>で用いたデータに対してラッソ回帰を評価してください。`sklearn_linear`モジュールの`Lasso`クラスを使います。なお、Lassoクラスにはパラメータ設定し、変更できるので調べてみてください。具体的には以下の公式ドキュメントをみてください。\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rpwf-xQyuKXZ"},"source":["## 5.5 決定木\n","キーワード：決定木、不純度、エントロピー、情報利得\n","\n","この節では**決定木（Decision Tree）**によるモデル構築方法を学びます。決定木は、ある目的に到達するためにデータの各属性の条件分岐を繰り返してクラス分けする方法です。目的変数がカテゴリの場合は**分類木**、数値の場合は**回帰木**と呼びます。\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"heWqz5EUuKXZ"},"source":["### 5.5.1 キノコデータセット"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IEDfRWYNuKXZ"},"source":["決定木の例として、次のURLから入手できるキノコのデータセットを使います。キノコには毒キノコとそうでないもの（食用キノコ）があります。\n","\n","http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\n","\n","ここでの目的は、与えられたキノコが毒キノコか否かを見分けることです。キノコの説明変数はカサの形、匂い、ヒダの大きさや色など計20種類以上あります。これらの説明変数を用いて、たとえば、かさの形が円錐形かそうでないか、ヒダの色が黒色なのか赤色なのか、その大きさは大きいのか小さいのかというように条件分岐をしていき、最終的にそのキノコが毒キノコなのか否かを見分けようと試みるとします。この例では、毒キノコか否かというように、目的変数がカテゴリ変数であるので分類木の例ということになります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FjnROW7iuKXZ"},"source":["このように、ある目的（毒キノコか否かなど）に到達するために、データの各属性の条件分岐を繰り返してカテゴリ分けするというのが決定木の手法です。目的に辿りつくさまざまなルートがあり、それがツリー形式で表現されるため決定木という名前が付けられています。\n","\n","まずは、キノコデータセットを読み込んで、その先頭を表示することでデータを確認しましょう。"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1663935882139,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"Egw4AWUguKXZ","outputId":"30d744c8-7194-4492-a11a-67dd9e6234e2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>classes</th>\n","      <th>cap_shape</th>\n","      <th>cap_surface</th>\n","      <th>cap_color</th>\n","      <th>odor</th>\n","      <th>bruises</th>\n","      <th>gill_attachment</th>\n","      <th>gill_spacing</th>\n","      <th>gill_size</th>\n","      <th>gill_color</th>\n","      <th>...</th>\n","      <th>stalk_surface_below_ring</th>\n","      <th>stalk_color_above_ring</th>\n","      <th>stalk_color_below_ring</th>\n","      <th>veil_type</th>\n","      <th>veil_color</th>\n","      <th>ring_number</th>\n","      <th>ring_type</th>\n","      <th>spore_print_color</th>\n","      <th>population</th>\n","      <th>habitat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>p</td>\n","      <td>x</td>\n","      <td>s</td>\n","      <td>n</td>\n","      <td>t</td>\n","      <td>p</td>\n","      <td>f</td>\n","      <td>c</td>\n","      <td>n</td>\n","      <td>k</td>\n","      <td>...</td>\n","      <td>s</td>\n","      <td>w</td>\n","      <td>w</td>\n","      <td>p</td>\n","      <td>w</td>\n","      <td>o</td>\n","      <td>p</td>\n","      <td>k</td>\n","      <td>s</td>\n","      <td>u</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>e</td>\n","      <td>x</td>\n","      <td>s</td>\n","      <td>y</td>\n","      <td>t</td>\n","      <td>a</td>\n","      <td>f</td>\n","      <td>c</td>\n","      <td>b</td>\n","      <td>k</td>\n","      <td>...</td>\n","      <td>s</td>\n","      <td>w</td>\n","      <td>w</td>\n","      <td>p</td>\n","      <td>w</td>\n","      <td>o</td>\n","      <td>p</td>\n","      <td>n</td>\n","      <td>n</td>\n","      <td>g</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>e</td>\n","      <td>b</td>\n","      <td>s</td>\n","      <td>w</td>\n","      <td>t</td>\n","      <td>l</td>\n","      <td>f</td>\n","      <td>c</td>\n","      <td>b</td>\n","      <td>n</td>\n","      <td>...</td>\n","      <td>s</td>\n","      <td>w</td>\n","      <td>w</td>\n","      <td>p</td>\n","      <td>w</td>\n","      <td>o</td>\n","      <td>p</td>\n","      <td>n</td>\n","      <td>n</td>\n","      <td>m</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>p</td>\n","      <td>x</td>\n","      <td>y</td>\n","      <td>w</td>\n","      <td>t</td>\n","      <td>p</td>\n","      <td>f</td>\n","      <td>c</td>\n","      <td>n</td>\n","      <td>n</td>\n","      <td>...</td>\n","      <td>s</td>\n","      <td>w</td>\n","      <td>w</td>\n","      <td>p</td>\n","      <td>w</td>\n","      <td>o</td>\n","      <td>p</td>\n","      <td>k</td>\n","      <td>s</td>\n","      <td>u</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>e</td>\n","      <td>x</td>\n","      <td>s</td>\n","      <td>g</td>\n","      <td>f</td>\n","      <td>n</td>\n","      <td>f</td>\n","      <td>w</td>\n","      <td>b</td>\n","      <td>k</td>\n","      <td>...</td>\n","      <td>s</td>\n","      <td>w</td>\n","      <td>w</td>\n","      <td>p</td>\n","      <td>w</td>\n","      <td>o</td>\n","      <td>e</td>\n","      <td>n</td>\n","      <td>a</td>\n","      <td>g</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 23 columns</p>\n","</div>"],"text/plain":["  classes cap_shape cap_surface cap_color odor bruises gill_attachment   \n","0       p         x           s         n    t       p               f  \\\n","1       e         x           s         y    t       a               f   \n","2       e         b           s         w    t       l               f   \n","3       p         x           y         w    t       p               f   \n","4       e         x           s         g    f       n               f   \n","\n","  gill_spacing gill_size gill_color  ... stalk_surface_below_ring   \n","0            c         n          k  ...                        s  \\\n","1            c         b          k  ...                        s   \n","2            c         b          n  ...                        s   \n","3            c         n          n  ...                        s   \n","4            w         b          k  ...                        s   \n","\n","  stalk_color_above_ring stalk_color_below_ring veil_type veil_color   \n","0                      w                      w         p          w  \\\n","1                      w                      w         p          w   \n","2                      w                      w         p          w   \n","3                      w                      w         p          w   \n","4                      w                      w         p          w   \n","\n","  ring_number ring_type spore_print_color population habitat  \n","0           o         p                 k          s       u  \n","1           o         p                 n          n       g  \n","2           o         p                 n          n       m  \n","3           o         p                 k          s       u  \n","4           o         e                 n          a       g  \n","\n","[5 rows x 23 columns]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# データを取得\n","url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'\n","res = requests.get(url).content\n","\n","# 取得したデータをDataFrameオブジェクトとして読み込み\n","mushroom = pd.read_csv(io.StringIO(res.decode('utf-8')), header=None)\n","\n","# データの列にラベルを設定\n","mushroom.columns = ['classes', 'cap_shape', 'cap_surface', 'cap_color', 'odor', 'bruises',\n","                             'gill_attachment','gill_spacing','gill_size','gill_color','stalk_shape',\n","                             'stalk_root','stalk_surface_above_ring','stalk_surface_below_ring',\n","                             'stalk_color_above_ring','stalk_color_below_ring','veil_type','veil_color',\n","                             'ring_number','ring_type','spore_print_color','population', 'habitat']\n","\n","# 先頭5行を表示\n","mushroom.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"E6lTETuhuKXZ"},"source":["それぞれの変数の内容は、以下URLの`agaricus-lepiota.names`に記載されています。\n","\n","http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nQMVWrDKuKXZ"},"source":["     1. cap-shape:                bell=b,conical=c,convex=x,flat=f,\n","                                  knobbed=k,sunken=s\n","     2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s\n","     3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r,\n","                                  pink=p,purple=u,red=e,white=w,yellow=y\n","     4. bruises?:                 bruises=t,no=f\n","     5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f,\n","                                  musty=m,none=n,pungent=p,spicy=s\n","     6. gill-attachment:          attached=a,descending=d,free=f,notched=n\n","     7. gill-spacing:             close=c,crowded=w,distant=d\n","     8. gill-size:                broad=b,narrow=n\n","     9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g,\n","                                  green=r,orange=o,pink=p,purple=u,red=e,\n","                                  white=w,yellow=y\n","    10. stalk-shape:              enlarging=e,tapering=t\n","    11. stalk-root:               bulbous=b,club=c,cup=u,equal=e,\n","                                  rhizomorphs=z,rooted=r,missing=?\n","    12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n","    13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n","    14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o,\n","                                  pink=p,red=e,white=w,yellow=y\n","    15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o,\n","                                  pink=p,red=e,white=w,yellow=y\n","    16. veil-type:                partial=p,universal=u\n","    17. veil-color:               brown=n,orange=o,white=w,yellow=y\n","    18. ring-number:              none=n,one=o,two=t\n","    19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l,\n","                                  none=n,pendant=p,sheathing=s,zone=z\n","    20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r,\n","                                  orange=o,purple=u,white=w,yellow=y\n","    21. population:               abundant=a,clustered=c,numerous=n,\n","                                  scattered=s,several=v,solitary=y\n","    22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p,\n","                                  urban=u,waste=w,woods=d"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"br4RPkaduKXZ"},"source":["目的変数は`classes`です。これが`p`の場合は毒キノコ、`e`の場合は食用であることを示します。1つの行が1つのキノコの情報で、属性（`cap_shape`や`cap_surface`など）がそれぞれ付いています。たとえば、1つ目の行のキノコは`classes`が`p`なので毒キノコで、`cap_shape`（カサの形）は`x`（`convex`/饅頭型）になっています。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dqC3GWFEuKXZ"},"source":["また下記のプログラムを実行することで、データは8124行、23列で構成され、欠損値はないことがわかります。"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1635295692057,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"LkGHLwS1uKXZ","outputId":"4105b6ff-e57d-45e5-faae-612522602632"},"outputs":[{"name":"stdout","output_type":"stream","text":["データの形式:(8124, 23)\n","欠損の数:0\n"]}],"source":["print('データの形式:{}'.format(mushroom.shape))\n","print('欠損の数:{}'.format(mushroom.isnull().sum().sum()))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UBIH_VQquKXa"},"source":["### 5.5.2 データの整理\n","\n","たくさんの説明変数がありますが、以下では話を簡単にするため、説明変数を`gill_color`（ひだの色）、`gill_attachment`（ひだの付き方）、`odor`（匂い）、`cap_color`（かさの色）の4つに限定することにします。これらのデータは、上記表示の通り、たとえば`gill_color`は`black`のときはk、`brown`のときはnといったカテゴリ変数となっています。決定木で扱う変数は、説明変数、目的変数、ともに数値変数でなければなりません。このようにカテゴリ変数のときは数値変数に変換しなければなりません。\n","\n","そこでカテゴリ変数をダミー変数化することとします。ダミー変数化するというのは、たとえば性別変数の列に`male`か`female`の値が入っている場合、性別の列を`male`列と`female`列の2列に分けて表現することを言います。より具合的には、性別の値が`male`であった場合は`male`列を1、`female`列を0にすることです（他に`one-hot`化する、`one-hot`エンコーディングを施すなどとも言います）。Pandasの`get_dummies`関数を用いると、ダミー変数化できます。"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1663935900233,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"5iwxLXjEuKXa","outputId":"e742b0ee-3215-46bb-d7f8-d060a41721e0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gill_color_b</th>\n","      <th>gill_color_e</th>\n","      <th>gill_color_g</th>\n","      <th>gill_color_h</th>\n","      <th>gill_color_k</th>\n","      <th>gill_color_n</th>\n","      <th>gill_color_o</th>\n","      <th>gill_color_p</th>\n","      <th>gill_color_r</th>\n","      <th>gill_color_u</th>\n","      <th>...</th>\n","      <th>cap_color_b</th>\n","      <th>cap_color_c</th>\n","      <th>cap_color_e</th>\n","      <th>cap_color_g</th>\n","      <th>cap_color_n</th>\n","      <th>cap_color_p</th>\n","      <th>cap_color_r</th>\n","      <th>cap_color_u</th>\n","      <th>cap_color_w</th>\n","      <th>cap_color_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>"],"text/plain":["   gill_color_b  gill_color_e  gill_color_g  gill_color_h  gill_color_k   \n","0         False         False         False         False          True  \\\n","1         False         False         False         False          True   \n","2         False         False         False         False         False   \n","3         False         False         False         False         False   \n","4         False         False         False         False          True   \n","\n","   gill_color_n  gill_color_o  gill_color_p  gill_color_r  gill_color_u  ...   \n","0         False         False         False         False         False  ...  \\\n","1         False         False         False         False         False  ...   \n","2          True         False         False         False         False  ...   \n","3          True         False         False         False         False  ...   \n","4         False         False         False         False         False  ...   \n","\n","   cap_color_b  cap_color_c  cap_color_e  cap_color_g  cap_color_n   \n","0        False        False        False        False         True  \\\n","1        False        False        False        False        False   \n","2        False        False        False        False        False   \n","3        False        False        False        False        False   \n","4        False        False        False         True        False   \n","\n","   cap_color_p  cap_color_r  cap_color_u  cap_color_w  cap_color_y  \n","0        False        False        False        False        False  \n","1        False        False        False        False         True  \n","2        False        False        False         True        False  \n","3        False        False        False         True        False  \n","4        False        False        False        False        False  \n","\n","[5 rows x 26 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["mushroom_dummy = pd.get_dummies(mushroom[['gill_color', 'gill_attachment', 'odor', 'cap_color']])\n","mushroom_dummy.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iORkyO8nuKXa"},"source":["上記の通り変換後のデータは、元の変数名と値の組み合わせになります。たとえば、`gill_color_k`に1が立っていたら、`gill_color`が`k`であったことを意味します。ダミー変数化はこのようにカテゴリ変数をフラグ化（数量化）したいときに使える最もシンプルな方法です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4Ga4G-XuuKXa"},"source":["次に目的変数である`classes`についても新しい変数`flg`に変換しておきます。カテゴリを表す目的変数であっても、入力データ形式が数値である必要があるためです。行っている処理は`classes`変数の値が`p`の場合は1、そうでない場合は0として（`lambda`関数の部分）、新しい変数`flg`を追加しています。そして`map`関数を使うことでその処理をすべての要素（セル）に適用しています。ここまでで目的変数を0/1の数値型で表現し直し、カテゴリ変数の特徴量もダミー変数化したので、決定木（アルゴリズム）に入力することができるようになりました。"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Lyaw6rhRuKXa"},"outputs":[],"source":["# 目的変数もフラグ化（0/1化）する\n","mushroom_dummy['flg'] = mushroom['classes'].map(lambda x: 1 if x =='p' else 0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BPXz0OZiuKXa"},"source":["### 5.5.3 エントロピー：不純度の指標"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AxAPZewruKXa"},"source":["決定木のモデル構築の前に、決定木の作られ方をカテゴリ識別の不純度（`impurity`）という視点から見ることとします。不純度とは、毒キノコか否かの識別の状態を表す指標で、不純度が高いことはカテゴリ識別ができていない状態を意味します。たとえば、`cap_color`が`c`であるかそうでないかの`TRUE`（1） or `FALSE`（0）でデータを分けるとして、その時にそれぞれ毒キノコがどれくらいあるのかをクロス集計してみます。下記表は行が`cap_color`がcであるか（1）、そうでないか（0）、列が毒フラグ`flg`が立っているか（1）、そうでないか（0）のクロス集計結果です。"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1663935904869,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"Gx42uyh-uKXa","outputId":"8a13e4e0-a73c-4f37-d2b5-12114ce102a4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>flg</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","    <tr>\n","      <th>cap_color_c</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>False</th>\n","      <td>4176</td>\n","      <td>3904</td>\n","    </tr>\n","    <tr>\n","      <th>True</th>\n","      <td>32</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["flg             0     1\n","cap_color_c            \n","False        4176  3904\n","True           32    12"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["mushroom_dummy.groupby(['cap_color_c', 'flg'])['flg'].count().unstack()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"suC1UfBVuKXa"},"source":["上表より、`cap_color`が`c`（`cap_color_c`が1）であれば、毒（`flg`が1）の数が12個で、毒でない（`flg`が0）数が32個であることがわかります。\n","そして`cap_color`が`c`でなければ（`cap_color_c`が0）、毒（`flg`が1）の数が3904個で、毒でない（`flg`が0）数が4176個とわかります。\n","\n","この結果をみると、`cap_color`が`c`であるか否かの情報は、毒キノコを見分けるのにあまり役に立たなそうです。なぜなら、どちらを選んでも毒キノコが一定の割合で含まれているからです。\n","\n","一方、別の変数`gill_color`が`b`であるかそうでないかの`TRUE`（1） or `FALSE`（0）で分けた場合のクロス集計結果は以下となります。"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1663935907070,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"Qwj2ofHBuKXa","outputId":"fcb4eb4d-dff2-448c-b162-e1074f9e7b88"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>flg</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","    <tr>\n","      <th>gill_color_b</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>False</th>\n","      <td>4208.0</td>\n","      <td>2188.0</td>\n","    </tr>\n","    <tr>\n","      <th>True</th>\n","      <td>NaN</td>\n","      <td>1728.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["flg                0       1\n","gill_color_b                \n","False         4208.0  2188.0\n","True             NaN  1728.0"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["mushroom_dummy.groupby(['gill_color_b', 'flg'])['flg'].count().unstack()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qEq7V1lpuKXa"},"source":["上表より、`gill_color`が`b`（`gill_color_b`が1）であれば、毒（`flg`が1）の数が1728個で、毒でない（`flg`が0）数が0個（ないので`NaN`）であることが分かります。\n","そして`gill_color`が`b`でなければ（`gill_color_b`が0）、毒（`flg`が1）の数が2188個で、毒でない（`flg`が0）数が4208個とわかります。\n","\n","先程の分岐条件と比べると、`gill_color`が`b`であるか否かの分岐条件の方が、識別能力の高い（不純度の低い識別状態を導く）有益な条件だとわかります。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NeJMsaJAuKXa"},"source":["ここでは2つの変数の例（`cap_color_c`と`gill_color_b`）で考えましたが、他にもさまざまな変数があり、それぞれに対して上のような条件分岐を考えることができます。このように決定木とは、多数の変数の中でどの変数から最も有益な条件分岐を得られるかを見分けてくれるアルゴリズムで、その分岐条件の優劣を決める際に不純度が使われています。そして、その不純度の指標としてよく使われるものに**エントロピー（entropy）**があります。エントロピーの定義は以下の式$H(S)$で与えられます。$S$はデータの集合、$n$はカテゴリの数、$p_i$は各カテゴリに属するデータサンプルの割合です。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bkIMhwdyuKXa"},"source":["\\begin{eqnarray}\n","\\ H(S)= -\\sum^n_{i=1}(p_i\\log_{2}p_i)\n","\\end{eqnarray}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Tbz28bwiuKXa"},"source":["今回の例ではカテゴリは2つ（毒キノコか否か）で、毒キノコでない割合が$p_1$、毒キノコである割合が$p_2$となります。ここで1つ目の例として、ある分岐条件によって毒キノコも食用キノコも等しい割合で入っている状態を考えます。$p_1=p_2=0.5$となるので、エントロピーは上の式から以下のように計算できます。なお、底が2のログ関数（`np.log2`）を使っています。"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":375,"status":"ok","timestamp":1663935919889,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"cWnhC6zvuKXa","outputId":"9191a6f8-1ae1-437a-cc2c-fb4cdd5b1018"},"outputs":[{"data":{"text/plain":["1.000"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["- (0.5 * np.log2(0.5) + 0.5 * np.log2(0.5))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"g2xp7dMluKXa"},"source":["上記より、エントロピーが1.0になることが確認されました。実は、データとしての乱雑さが最大となる場合、エントロピーは1.0となります。毒キノコもそうでないキノコも等しい割合（0.5）で含まれているので、全く識別ができていない状態ということです。次に、毒キノコでない割合`p1=0.001`、毒キノコである割合が`p2=0.999`の場合を考えてみます。"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1663935921699,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"Y0FbS-BOuKXa","outputId":"609a4cb7-98d5-4310-b8eb-24e3c3e6ec20"},"outputs":[{"data":{"text/plain":["0.011"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["- (0.001 * np.log2(0.001) + 0.999 * np.log2(0.999))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xKK_Q2rguKXa"},"source":["上記の通り、エントロピーは0に近い値になっているのがわかります。この状態は、ほぼデータは毒キノコと特定できているのでエンロトピーは小さくなっているのです。まとめると、エントロピーは1.0に近いと識別ができていない状態、0.0に近ければ識別がよくできている状態と言えるのです。なお、今回の例では、カテゴリは2分類のため $p_1 = 1 - p_2$ という関係式ができるので、エントロピーの式は以下のように表せます。"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"A_Xr_WCPuKXa"},"outputs":[],"source":["def calc_entropy(p):\n","    return - (p * np.log2(p) + (1 - p) *  np.log2(1 - p) )"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3_wpQtFquKXa"},"source":["`p`は確率で0から1までの値を取るので、この`p`とエントロピーの式をグラフで表すと以下のようになります。エントロピーは最大で1、最小で0となることが確認できます。"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1663935925812,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"YkMrv2_uuKXa","outputId":"9224674e-b7fe-40a6-d543-8110ddf9fd3e","scrolled":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# pの値を0.001から0.999まで0.01刻みで動かす\n","p = np.arange(0.001, 0.999, 0.01)\n","\n","# グラフ化\n","plt.plot(p, calc_entropy(p)) \n","plt.xlabel('prob')\n","plt.ylabel('entropy')\n","plt.grid(True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XIGe-j6nuKXa"},"source":["ここまでの説明で、エントロピーが識別の不純度を表すということを説明しました。先ほどのキノコのデータでエントロピーを計算してみましょう。扱っているデータセットは合計で8124行ありました。目的変数`flg`がカテゴリを表すので、そのデータをカウントします。"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1663935927871,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"yqgPafheuKXb","outputId":"6843e0a0-b156-44a0-c16b-de368be711e8"},"outputs":[{"data":{"text/plain":["flg\n","0    4208\n","1    3916\n","Name: flg, dtype: int64"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["mushroom_dummy.groupby('flg')['flg'].count()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Fca1NcPMuKXb"},"source":["上記より、毒でないキノコ（0）は4208個、毒キノコ（1）は3916個とわかります。よって毒キノコでない割合は0.518（=4208/8124）、毒キノコである割合は0.482（=3916/8124）となるので、エントロピーの初期値は以下の通り、0.999であることがわかります。"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1663935928897,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"Mv-HAGWTuKXb","outputId":"c0ff00e5-5c13-4954-dfa3-202108ec4772","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["毒キノコデータのエントロピーの初期値: 0.999\n"]}],"source":["entropy_init = - (0.518 * np.log2(0.518) + 0.482 * np.log2(0.482))\n","print('毒キノコデータのエントロピーの初期値: {:.3f}'.format(entropy_init))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4EtVg6UTuKXb"},"source":["### 5.5.4 情報利得：分岐条件の有益さを測る"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"D6ldblgvuKXb"},"source":["エントロピーは1に近いほど識別がされていない状態、0に近いほど識別がよくされている状態でした。次に考えるべきことは、どの説明変数を分岐に用いたら不純度（キノコデータでは初期時点で0.999）をより小さくできるのかということです。そこで押さえるべき概念が**情報利得（information gain）**です。情報利得とは、ある変数を使ってデータ分割するとき、そのデータ分割前後でどれだけエントロピーが減少したかを表す指標です。先程と同様、`cap_color_c`と`gill_color_b`の2つの変数を使い、どちらの変数が分岐条件として有益なのかを情報利得を用いて示します。まず、`cap_color`が`c`であるか否かの2つのグループに分岐し、それぞれにおける毒キノコ割合を計算しエントロピーを計算してみます。"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1663935930621,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"Oql-YaMDuKXb","outputId":"f480149a-b2b3-44e2-a39d-73c747045bad","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>flg</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","    <tr>\n","      <th>cap_color_c</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>False</th>\n","      <td>4176</td>\n","      <td>3904</td>\n","    </tr>\n","    <tr>\n","      <th>True</th>\n","      <td>32</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["flg             0     1\n","cap_color_c            \n","False        4176  3904\n","True           32    12"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["mushroom_dummy.groupby(['cap_color_c', 'flg'])['flg'].count().unstack()"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1663935931642,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"YN5LBdlnuKXb","outputId":"e3ea5cd9-4463-4565-a6b7-ac3cd15f46ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["entropy_c0: 0.999\n"]}],"source":["# cap_colorがcでない場合のエントロピー\n","p1 = 4176 / (4176 + 3904)\n","p2 = 1 - p1\n","entropy_c0 = - (p1 * np.log2(p1) + p2 * np.log2(p2))\n","print('entropy_c0: {:.3f}'.format(entropy_c0))"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663935933194,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"V_qr06OjuKXb","outputId":"ae7dc394-8bc1-45bb-9110-0238f10c2626"},"outputs":[{"name":"stdout","output_type":"stream","text":["entropy_c1: 0.845\n"]}],"source":["# cap_colorがcである場合のエントロピー\n","p1 = 32 / (32 + 12)\n","p2 = 1 - p1\n","entropy_c1 = - (p1 * np.log2(p1) + p2 * np.log2(p2))\n","print('entropy_c1: {:.3f}'.format(entropy_c1))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"B7_ztIDzuKXb"},"source":["分割する前の全体のエントロピーは0.999でした。ここで分割する前のデータを親データセット、分割したデータを子のデータセットと呼ぶとした場合、情報利得を「**親データセットのエントロピー - Σ{(子データセットのサイズ/親データセットのサイズ)×子のデータセットのエントロピー}**」と定義します。この値が大きければ大きいほど、分割前後でエントロピーの低下が大きいため、より有益な分岐条件であるとわかるのです。実際に、Σ{(子データセットのサイズ/親データセットのサイズ)×子のデータセットのエントロピー}の部分を計算すると、次のようになります。"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":974,"status":"ok","timestamp":1663935935826,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"pS5Bs_EtuKXb","outputId":"faa3cd89-2656-40de-b28d-fd67efa23635"},"outputs":[{"name":"stdout","output_type":"stream","text":["データ分割後の平均エントロピー: 0.998\n"]}],"source":["entropy_after = (4176 + 3904) / 8124 * entropy_c0 + (32 + 12) / 8124 * entropy_c1\n","print('データ分割後の平均エントロピー: {:.3f}'.format(entropy_after))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HE8DtGdxuKXb"},"source":["この結果、情報利得はデータ分割前後のエントロピーの差として、以下の通り0.001であることが確認でき、あまりエントロピーが減少していないことがわかります。cap_colorがcかどうかはそれほど有益な分岐条件ではなさそうということを定量的に表現できました。"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1635295692456,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"gfV7_0p_uKXb","outputId":"a37be4d8-eda7-4215-e375-cafbc92b9a11"},"outputs":[{"name":"stdout","output_type":"stream","text":["変数cap_colorの分割によって得られる情報利得: 0.001\n"]}],"source":["print('変数cap_colorの分割によって得られる情報利得: {:.3f}'.format(entropy_init - entropy_after))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vFCba3aVuKXb"},"source":["一方、`gill_color`が`b`であるかどうかの情報利得を計算すると、以下の通り0.269となります。上記の分岐条件よりもエントロピーを大きく低下させられる、より有益な分岐条件とわかります。下記で一点留意されたいのは、`gill_color`が`b`である場合のエントロピーの計算です。エントロピーの定義は、厳密には空ではないカテゴリについて計算するという条件があります。`gill_color`が`b`である場合、`flg`変数が0となるサンプルはありませんから、エントロピー計算の$Σ$に$p1*np.log2(p1)$を含めていません。"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1635295692457,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"2Qlyw0O1uKXb","outputId":"62c6b43a-92e5-423b-8e3e-26fbf630d097"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>flg</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","    <tr>\n","      <th>gill_color_b</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>False</th>\n","      <td>4208.0</td>\n","      <td>2188.0</td>\n","    </tr>\n","    <tr>\n","      <th>True</th>\n","      <td>NaN</td>\n","      <td>1728.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["flg                0       1\n","gill_color_b                \n","False         4208.0  2188.0\n","True             NaN  1728.0"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["mushroom_dummy.groupby(['gill_color_b', 'flg'])['flg'].count().unstack()"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1635295692457,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"qTrqBU7suKXb","outputId":"4ef1cd55-c06f-40e3-c050-43ccae3f822e"},"outputs":[{"name":"stdout","output_type":"stream","text":["変数gill_colorの分割によって得られる情報利得: 0.269\n"]}],"source":["# gill_colorがbでない場合のエントロピー\n","p1 = 4208 / (4208 + 2188)\n","p2 = 1 - p1\n","entropy_b0 = - (p1 * np.log2(p1) + p2 * np.log2(p2))\n","\n","# gill_colorがbである場合のエントロピー\n","p1 = 0 / (0 + 1728)\n","p2 = 1 - p1\n","entropy_b1 = - (p2 * np.log2(p2))\n","\n","entropy_after = (4208 + 2188) / 8124 * entropy_b0 + (0 + 1728) / 8124 * entropy_b1\n","print('変数gill_colorの分割によって得られる情報利得: {:.3f}'.format(entropy_init - entropy_after))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"55PG0mX_uKXb"},"source":["以上で決定木の生成プロセス（条件分岐の優劣の決め方）を確認しました。情報利得が一番大きい分岐条件でデータを分割し、更に分割先でも同様に情報利得を最大とする分岐条件を探索してくれるのが決定木であることを理解しましょう。これまで不純度を表す指標としてエントロピーを紹介しましたが、他にも**ジニ不純度（Gini impurity）、分類誤差（classification error）**などがあります。ジニ不純度は、確率・統計の総合問題で出てきたジニ係数と関わりがあります。本講義では詳細は割愛しますので、興味がある方は調べてみてください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GaTGbEQiuKXb"},"source":[">**[やってみよう]**\n",">\n",">ジニ不純度、分類誤差（誤分類率）について調べてみましょう。それぞれどんな指標でしょうか。また、決定木のモデルを構築するときに反映させるにはどうすればいいでしょうか。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bCsVOjPMuKXc"},"source":["なお前節（5.4 正則化項のある回帰：ラッソ回帰、リッジ回帰）において、モデルの複雑さについて言及しましたが、決定木の場合のモデルの複雑さは分岐数で決定されます。多くの分岐を許容するほど複雑なモデルになることを覚えておきましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_CJhR6QkuKXc"},"source":["### 5.5.5 決定木のモデル構築"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4lFgLR0cuKXc"},"source":["決定木の動きを理解したところで、決定木のモデル構築をしていきましょう。`sklearn.tree`モジュールの`DecisionTreeClassifier`クラスを使うことで、決定木モデルを構築できます。下記のプログラムでは`DescriptionTreeClasifier`クラスを使う際、パラメータの`criteroin`に'`entropy`'を指定することで、分岐条件の指標としてエントロピーを設定しています。"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1471,"status":"ok","timestamp":1663935942199,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"Z9GJl9wduKXc","outputId":"70294a9c-3318-4233-ebb3-ccf043e4ad2c","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["正解率(train):0.883\n","正解率(test):0.894\n"]}],"source":["from sklearn.tree import  DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","\n","# データ分割\n","X = mushroom_dummy.drop('flg', axis=1)\n","y = mushroom_dummy['flg']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","\n","# 決定木クラスの初期化と学習\n","model = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n","model.fit(X_train, y_train)\n","\n","print('正解率(train):{:.3f}'.format(model.score(X_train, y_train)))\n","print('正解率(test):{:.3f}'.format(model.score(X_test, y_test)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6fQye2SPuKXc"},"source":["結果はテストデータで89%ほどの正解率です。決定木の分岐数決定のパラメータに`max_depth`があり、上記では5にしています。深ければ当然、条件分岐数の上限も増えます。正解率を高めるべくより複雑なモデルにしたい場合は深い木を作ればよいでしょう（ただし、あまり深い木を作ると過学習の危険性が増すので注意しましょう）。また決定木は、モデルを構築する際に他のモデルでは必須となる標準化処理をしなくても結果は変わりません。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BkRPZRz9uKXc"},"source":["なお参考ですが、以下のように決定木の結果を可視化できます（このプログラムを実行するには`pydotplus`と`graphviz`のパッケージをインストールしておく必要がありますが、環境の設定が難しいため、本講義では割愛します。）。\n","\n","下記の可視化した結果を見るとわかるように、条件分岐が繰り返され、2分木の形になっていることがわかります。木に書かれている四角形は上から読みます。一番上の変数（$X[0]$、ここでは説明変数の1番目のカラムの`gill_color_b`）が0.5より大きいときには右の`False`に進み、その子データセットのサンプル数は1302になり、エントロピーは0になっています。これは`gill_color_b`のフラグが1（$X[0]<=0.5$は`False`になる）のときは、毒キノコになるという分岐に相当します。"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":736},"executionInfo":{"elapsed":1703,"status":"ok","timestamp":1663935958824,"user":{"displayName":"Masataka ISHIDA","userId":"17603399018278840160"},"user_tz":-540},"id":"EvCxfDtnuKXc","outputId":"343f7364-26f3-47da-e7c8-94fc2ba21857"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pydotplus'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 参考プログラム\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# pydotplusやgraphvizをインストールする必要があります\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m tree\n\u001b[1;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydotplus\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mimport\u001b[39;00m StringIO\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"]}],"source":["# 参考プログラム\n","# pydotplusやgraphvizをインストールする必要があります\n","from sklearn import tree\n","import pydotplus\n","from six import StringIO\n","from IPython.display import Image\n","\n","dot_data = StringIO()\n","tree.export_graphviz(model, out_file=dot_data)\n","graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n","Image(graph.create_png())  "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gcTp7ktFuKXc"},"source":["参考文献「ビジネス視点で機械学習を活かすのに役立つ書籍」の『戦略的データサイエンス入門 ―ビジネスに活かすコンセプトとテクニック』は、この決定木を説明するのに参考にした書籍です。他の項目でも紹介しましたが、わかりやすく書いてあるのでオススメです。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ye55NI2YuKXc"},"source":["####  <練習問題 5-6>\n","`sklearn.datasets`モジュールの`load_breast_cancer`関数から乳がんデータを読み込み、目的変数を`cancer.target`、説明変数を`cancer.data`として、決定木のモデルを構築し、訓練スコアとテストスコアを確認してください。木の深さなどのパラメータを変更し結果を比較してみてください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NxBIT9iVuKXc"},"source":["## 5.6 k-NN（k近傍法）\n","キーワード：k-NN、怠惰学習、memory-based learning"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-Ey_q6lCuKXc"},"source":["本節では、**k-NN（k-Nearest Neighbor：k近傍法）**について学びます。たとえば、あるグループAとグループBがあり、その人たちの属性がわかっているとして、どちらのグループに属するか分からない新しい人が来たケースを考えます。\n","\n","ここでその人がAとBのどちらのグループに属するか考える際、その人と属性が近いk人を選び、その人たちがグループAに多いのかそれともグループBに多いのかを調べて、多い方を新しい人のグループにするというのがk-NNによる分類方法です。k-NNのkは決定に利用する人数に相当します。k-NNは怠惰学習やmemory-based learningとも言われ、訓練データをそのまま覚えて学習します。\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tjgsYtzxuKXc"},"source":["### 5.6.1 k-NNのモデル構築\n","\n","それでは、k-NNを使ってモデル構築をしていきましょう。`sklearn.neibors`モジュールの`KNeighborsClassifier`クラスを使います。データ例としては乳がんに関するデータセットを使います。乳がんに関するデータセットは`load_breast_cancer`関数で取得できます。\n","\n","ここでは`k`を1から20まで変化させ、訓練データとテストデータの正解率の変化を見ています。`k`が小さい時は正解率に乖離がありますが、6～8あたりで訓練とテストの正解率が近くなります。それ以上増やしてもモデル精度に大きな変化は見られません。精度に改善が見られない場合、あまりkを大きくする必要はないので、本ケースにおいては6～8程度に設定しておくのが良さそうです。なお、以下は分類タスクにおけるモデル構築の例ですが、回帰の場合は`KNeighborsRegressor`クラスを使います。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":504,"status":"ok","timestamp":1635295694017,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"RnR6mUEbuKXc","outputId":"0e29a259-64ff-44df-bfc3-fa81a34209cc"},"outputs":[{"data":{"text/plain":["<matplotlib.legend.Legend at 0x7f3ea9d933d0>"]},"execution_count":41,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# データやモデルを構築するためのライブラリ等のインポート\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.neighbors import  KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","\n","# データセットの読み込み\n","cancer = load_breast_cancer()\n","\n","# 訓練データとテストデータに分ける\n","# stratifyは層化別抽出\n","X_train, X_test, y_train, y_test = train_test_split(\n","    cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n","\n","# グラフ描画用のリストを用意\n","training_accuracy = []\n","test_accuracy = []\n","\n","# 学習\n","for n_neighbors in range(1, 21):\n","    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    model.fit(X_train, y_train)\n","    training_accuracy.append(model.score(X_train, y_train))\n","    test_accuracy.append(model.score(X_test, y_test))\n","\n","# グラフを描画\n","plt.plot(range(1, 21), training_accuracy, label='Training')\n","plt.plot(range(1, 21), test_accuracy, label='Test')\n","plt.ylabel('Accuracy')\n","plt.xlabel('n_neighbors')\n","plt.legend()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2Nbp1DEruKXc"},"source":[">**[やってみよう]**\n",">\n",">k-NNの回帰はどのように計算されるか調査してみましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DG01WhhauKXc"},"source":["####  <練習問題 5-7>\n","5.5「決定木」で扱ったキノコのデータに対してk-NNを使ってモデル構築して検証してみましょう。`k`パラメータを変更しながら実行してください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xpogon1SuKXc"},"source":["####  <練習問題 5-8>\n","以前使った学生のテスト結果のデータ（student-mat.csv）を用いて、目的変数を`G3`、説明変数を以下で定義する`X`（学生の属性データを使用）として、k-NNの`k`パラメータを変えながら、どの`k`が最適か考えてみましょう。\n","\n","目的変数は数値型での回帰となるので、`KNeighborsRegressor`を使ってください。回帰の場合、出力される値は近傍の`k`個のデータの平均になります。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pshc1JFQuKXc"},"outputs":[],"source":["# インポート\n","import requests, zipfile\n","import os\n","\n","# データがあるurlの指定\n","url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip'\n","\n","# データをurlから取得\n","r = requests.get(url, stream=True)\n","\n","# zipfile内のstudent-mat.csvをカレントディレクトリ内のdataディレクトリに展開\n","with zipfile.ZipFile(io.BytesIO(r.content)) as existing_zip:\n","    existing_zip.extract('student-mat.csv', 'data')\n","\n","# csvfileが存在するディレクトリ\n","data_dir = './data'\n","\n","# student-mat.csvのpathを取得\n","path = os.path.join(data_dir, 'student-mat.csv')\n","\n","student = pd.read_csv(path, sep=';')\n","X = student.loc[:, ['age', 'Medu', 'Fedu', 'traveltime', 'studytime'\n","                              , 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc'\n","                              , 'absences', 'G1', 'G2']].values"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"c9npo5khuKXc"},"source":["## 7.7 サポートベクターマシン\n","キーワード：サポートクター、マージン"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JEupgihauKXc"},"source":["**サポートベクターマシン（Support Vector Machine：SVM）**は、カテゴリを識別する境界線を、1本の線ではなく、マージンを持った線で引く手法です。たとえば、2つのグループを分ける境界線を引くとき、線の引き方は色々とあるのですが、それぞれのグループの中で最も境界線に近い点（サポートベクター）との距離（マージン）が最大化するように線を引くのがサポートベクターマシンです。\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jgAgki3uuKXd"},"source":["### 5.7.1 サポートベクターマシンのモデル構築\n","\n","サポートベクターマシンを使ってモデルを構築してみましょう。サポートベクターマシンは`sklearn.svm`モジュールの`LinearSVC`クラスを使います。ここではデータ例として、k-NNのモデル構築で使ったのと同じ乳がんに関するデータセットを使います。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1635295694632,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"kuba8zxXuKXd","outputId":"b0f39947-3fab-4118-dbb4-2bb74983863f"},"outputs":[{"name":"stdout","output_type":"stream","text":["正解率(train):0.932\n","正解率(test):0.930\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"]}],"source":["# SVMのライブラリ\n","from sklearn.svm import LinearSVC\n","\n","# 訓練データとテストデータを分けるライブラリ\n","from sklearn.model_selection import train_test_split\n","\n","# データの読み込み\n","cancer = load_breast_cancer()\n","\n","# 訓練データとテストデータに分ける\n","X_train, X_test, y_train, y_test = train_test_split(\n","    cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n","\n","# クラスの初期化と学習\n","model = LinearSVC()\n","model.fit(X_train, y_train)\n","\n","# 訓練データとテストデータのスコア\n","print('正解率(train):{:.3f}'.format(model.score(X_train, y_train)))\n","print('正解率(test):{:.3f}'.format(model.score(X_test, y_test)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Poah6BicuKXd"},"source":["サポートベクターマシンでは、標準化するとスコアが改善されることがあります。実際にやってみると改善していることがわかります。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1635295694632,"user":{"displayName":"Takuya Fukushima","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhR4LDFC_RMoC8DpM73KIZhKgCXA-oZ-HDU8R2wtw=s64","userId":"15264897430699553304"},"user_tz":-540},"id":"8MxzvptLuKXd","outputId":"37a0e79e-2b34-458d-9847-2653b0ae1708"},"outputs":[{"name":"stdout","output_type":"stream","text":["正解率(train):0.993\n","正解率(test):0.951\n"]}],"source":["# データの読み込み\n","cancer = load_breast_cancer()\n","\n","# 訓練データとテストデータに分ける\n","X_train, X_test, y_train, y_test = train_test_split(\n","    cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n","\n","# 標準化\n","sc = StandardScaler()\n","sc.fit(X_train)\n","X_train_std = sc.transform(X_train)\n","X_test_std = sc.transform(X_test)\n","\n","# クラスの初期化と学習\n","model = LinearSVC()\n","model.fit(X_train_std, y_train)\n","\n","# 訓練データとテストデータのスコア\n","print('正解率(train):{:.3f}'.format(model.score(X_train_std, y_train)))\n","print('正解率(test):{:.3f}'.format(model.score(X_test_std, y_test)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Sr0_EKgnuKXd"},"source":[">**[やってみよう]**\n",">\n",">サポートベクターマシンで回帰を実施する（連続変数を予測する）場合は、どのクラスでモデル構築できるか調べてみましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TdStvJbIuKXd"},"source":["以上で、教師あり学習の各種モデル構築の方法の説明は終わりです。それぞれの手法についてのモデル構築の流れと、機械学習モデルの評価の考え方（訓練データに使わないデータで評価する）についての理解を確認しましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7iPZRcs_uKXd"},"source":["####  <練習問題 7-9>\n","乳がんデータセットについて、`sklearn.svm`モジュールの`SVC`クラスを使って、`cancer.target`を予測するモデルを構築しましょう。`model = SVC(kernel='rbf', random_state=0, C=2)`としてみてください。モデルを構築したら、訓練データとテストデータに分けて標準化し、スコアを確認してください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vRdkctB9uKXd"},"source":["## 5.8 総合問題"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Gp7GEe2puKXd"},"source":["### ■ 総合問題5-1 教師あり学習の用語（1）\n","\n","教師あり学習に関する用語について、それぞれの役割や意味について述べてください。どのような場面で使いますか？ネットや参考文献等を使って調べてみてください。\n","- 回帰\n","- 分類\n","- 教師あり学習\n","- 重回帰分析\n","- ロジスティック回帰分析\n","- 正則化\n","- リッジ回帰\n","- ラッソ回帰\n","- 決定木\n","- エントロピー\n","- 情報利得\n","- k-NN法\n","- SVM\n","- ノーフリーランチ"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RdRnmy7duKXd"},"source":["### ■ 総合問題5-2 決定木\n","`sklearn.datasets`モジュールの`load_iris`関数を使ってアヤメの花のデータセットを読み込み、目的変数を`iris.target`、説明変数を`iris.data`として、決定木のモデルを使って予測と検証を実施してください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FtcKxhx5uKXd"},"source":["### ■ 総合問題5-3 ノーフリーランチ\n","これまで数学の成績データや乳がんデータなど、さまざまなデータを扱ってきました。これらのデータに対して、ロジスティック回帰分析やSVMなど今まで学んだモデルを試し、どれが一番スコアが高いかを確認しましょう。データによって、一番良いスコアが出るモデルは異なりますが、その特徴はどんなものか、考察してください。これをノーフリーランチといい、どんなデータに対しても、一番良いモデルになるモデルはないということを意味します。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xlkBsp1zau1S"},"source":["**謝辞**：以下4つのデータセット利用に関して\n","1. http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n","2. http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n","3. http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\n","4. https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\n","\n","引用元：Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)]. Irvine, CA: University of California, School of Information and Computer Science.\n","\n","- 4のデータセットの引用について追記：  \n","P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp.5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.\n","[http://www3.dsi.uminho.pt/pcortez/student.pdf](http://www3.dsi.uminho.pt/pcortez/student.pdf) "]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":["vYP8RTTRuKXY","bKpd3ShYuKXY","5OeD2o21uKXZ","C_NRh4jDuKXZ","MlZTWUCcuKXZ","Ye55NI2YuKXc","DG01WhhauKXc","7iPZRcs_uKXd","Gp7GEe2puKXd","RdRnmy7duKXd"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
