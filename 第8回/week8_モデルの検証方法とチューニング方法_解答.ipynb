{"cells":[{"cell_type":"markdown","metadata":{"nbpresent":{"id":"0d4629d5-02e5-446b-8945-77a14085a9db"},"id":"3vaMRBKIEuNI"},"source":["# Week 8 練習と総合問題解答"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgXwGhIuEuNM"},"outputs":[],"source":["# 途中で使用するため、あらかじめ読み込んでおいてください。\n","# データ加工・処理・分析ライブラリ\n","import numpy as np\n","import numpy.random as random\n","import pandas as pd\n","\n","# 可視化ライブラリ\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import seaborn as sns\n","%matplotlib inline\n","\n","# 機械学習ライブラリ\n","import sklearn\n","\n","# 小数第３位まで表示\n","%precision 3"]},{"cell_type":"markdown","metadata":{"id":"wrsWGuZ_EuNN"},"source":["#### <練習問題 8-1>\n","乳がんデータに対して、決定木以外のモデル（ロジスティック回帰分析など）を構築し、それぞれのモデルの評価スコアをk分割交差検証を使って取得しましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koKL_fILEuNO"},"outputs":[],"source":["# 解答\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","\n","cancer = load_breast_cancer()\n","model = LogisticRegression(random_state=0)\n","scores = cross_val_score(model, cancer.data, cancer.target, cv=5)\n","\n","print('Cross validation scores:{}'.format(scores))\n","print('Cross validation scores:{:.2f}+-{:.2f}'.format(scores.mean(), scores.std()))"]},{"cell_type":"markdown","metadata":{"id":"Mt51EeQQEuNO"},"source":["#### <練習問題 8-2>\n","乳がんデータに対して、決定木を使ってグリッドサーチと交差検証を実施してください。なお、決定木のパラメータは、木の深さとリーフに含まれるべき最小サンプル数、具体的には、`param_grid = {'max_depth': [2, 3, 4, 5], 'min_samples_leaf': [2, 3, 4, 5]}`と設定してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"nbpresent":{"id":"acd6ce4a-78c0-4a4d-a5a1-41836fa12bf9"},"id":"Ha8ecnc7EuNP"},"outputs":[],"source":["# 解答\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.tree import  DecisionTreeClassifier\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","\n","# データの読み込み\n","cancer = load_breast_cancer()\n","X_train, X_test, y_train, y_test = train_test_split(\n","    cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n","\n","# パラメータの設定\n","param_grid = {'max_depth': [2, 3, 4, 5], 'min_samples_leaf': [2, 3, 4, 5]}\n","model = DecisionTreeClassifier(random_state=0)\n","grid_search = GridSearchCV(model, param_grid, cv=5)\n","grid_search.fit(X_train,y_train)\n","\n","print('テストデータにおけるスコア:{:.2f}'.format(grid_search.score(X_test, y_test)))\n","print('スコアがベストなときのパラメータ:{}'.format(grid_search.best_params_))\n","print('スコアがベストなときのross-validation score:{:.2f}'.format(grid_search.best_score_))"]},{"cell_type":"markdown","metadata":{"id":"uS1vdfkDEuNQ"},"source":["#### <練習問題 8-3>\n","<練習問題 8-2>で使用した乳がんデータに対して、サポートベクターマシン以外のモデル（ロジスティック回帰分析など）を構築し、混同行列を作ってください。また、テストデータにおける正解率、適合率、再現率、F1値の値をScikit-learnの関数を使って取得して下さい。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZwRrRYmEuNR"},"outputs":[],"source":["# 解答\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","\n","cancer = load_breast_cancer()\n","X_train, X_test, y_train, y_test = train_test_split(\n","    cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n","\n","model = LogisticRegression(random_state=0)\n","model.fit(X_train,y_train)\n","y_pred = model.predict(X_test)\n","\n","print('Confution matrix:\\n{}'.format(confusion_matrix(y_test, y_pred)))\n","print('正解率:{:.3f}'.format(accuracy_score(y_test, y_pred)))\n","print('適合率:{:.3f}'.format(precision_score(y_test, y_pred)))\n","print('再現率:{:.3f}'.format(recall_score(y_test, y_pred)))\n","print('F1値:{:.3f}'.format(f1_score(y_test, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"lwi0qU-KEuNS"},"source":["#### <練習問題 8-4>\n","以前練習問題で使用したアヤメのデータ（iris）に対して、目的変数をiris.targetとしたSVCを用いた多クラス分類のモデルを作り、そのROC曲線とAUCを計算してください。多クラス分類のモデルを作るには、`sklearn.multiclass`モジュールの`OneVsRestClassifier`クラスを用いてください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFDrQp34EuNS"},"outputs":[],"source":["# 解答\n","#参照URL：http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py\n","\n","from sklearn import svm, datasets\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.multiclass import OneVsRestClassifier\n","\n","#　データの読み込み\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# 正解データのone-hot化\n","y = label_binarize(y, classes=[0, 1, 2])\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n","\n","# multi-class classification model\n","model = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True, random_state=0))\n","y_score = model.fit(X_train, y_train).predict_proba(X_test)\n","\n","# 3つそれぞれのクラスについて、1次元のデータにして、ROC曲線、AUCを算出する\n","fpr, tpr, _ = roc_curve(y_test.ravel(), y_score.ravel())\n","roc_auc = auc(fpr, tpr)\n","\n","# グラフ化する\n","plt.figure()\n","plt.plot(fpr, tpr, color='red', label='average ROC (area = {:.3f})'.format(roc_auc))\n","plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC')\n","plt.legend(loc='best')"]},{"cell_type":"markdown","metadata":{"id":"kbyPnNb4EuNU"},"source":["#### <練習問題 8-5>\n","アヤメのデータセットを対象にバギングを使って、目的変数（`iris.target`）を予測するモデルを構築し検証しましょう。また、パラメータとして何を調整しますか。調べて実行してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3qI6rE0EuNU"},"outputs":[],"source":["# 解答\n","\n","# 必要なライブラリ等の読み込み\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_iris\n","\n","# アイリスのデータの読み込み\n","iris = load_iris()\n","\n","# 訓練データとテストデータにわける\n","X_train, X_test, y_train, y_test = train_test_split(\n","    iris.data, iris.target, stratify = iris.target, random_state=0)\n","\n","# バギングのモデル生成\n","model = BaggingClassifier(\n","            KNeighborsClassifier(),\n","            n_estimators=10,\n","            max_samples=0.5,\n","            max_features=0.5)\n","\n","# モデルのフィッティング\n","model.fit(X_train, y_train)\n","\n","# それぞれのスコア\n","print('正解率(train):{} {:.3f}'.format(model.__class__.__name__ , model.score(X_train, y_train)))\n","print('正解率(test):{} {:.3f}'.format(model.__class__.__name__ , model.score(X_test, y_test)))"]},{"cell_type":"markdown","metadata":{"id":"mv17oSO2EuNV"},"source":["#### <練習問題 8-6>\n","アヤメのデータセットを対象にブースティング（`AdaBoostRegressor`クラス）を使って、目的変数（`iris.target`）を予測するモデルを構築し検証しましょう。また、パラメータとして何を調整しますか。調べて実行してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iirewJR8EuNV"},"outputs":[],"source":["# 解答\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_iris\n","\n","iris = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(\n","    iris.data, iris.target, stratify = iris.target, random_state=0)\n","\n","model = AdaBoostClassifier(n_estimators=50, learning_rate=1.0)\n","model.fit(X_train, y_train)\n","print('正解率(train):{} {:.3f}'.format(model.__class__.__name__ , model.score(X_train, y_train)))\n","print('正解率(test):{} {:.3f}'.format(model.__class__.__name__ , model.score(X_test, y_test)))"]},{"cell_type":"markdown","metadata":{"id":"FyHudxL8EuNW"},"source":["#### <練習問題 8-7>\n","アヤメのデータを対象にランダムフォレストと勾配ブースティングを使って、目的変数（`iris.target`）を予測するモデルを構築し検証しましょう。また、パラメータとして何を調整しますか。調べて実行してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_aVtfvglEuNW"},"outputs":[],"source":["# 解答\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_iris\n","\n","iris = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(\n","    iris.data, iris.target, stratify = iris.target, random_state=0)\n","\n","models = {\n","    'RandomForest': RandomForestClassifier(random_state=0),\n","    'GradientBoost': GradientBoostingClassifier(random_state=0) \n","}\n","\n","scores = {}\n","for model_name, model in models.items():\n","    model.fit(X_train, y_train)\n","    scores[(model_name, 'train_score')] = model.score(X_train, y_train)\n","    scores[(model_name, 'test_score')] = model.score(X_test, y_test)\n","\n","pd.Series(scores).unstack()"]},{"cell_type":"markdown","metadata":{"nbpresent":{"id":"6b498642-823c-4eee-b6bb-fc237e248240"},"id":"Zr__ZU8mEuNW"},"source":["## 8.5 総合問題"]},{"cell_type":"markdown","metadata":{"nbpresent":{"id":"0950100e-332d-4f7d-a865-47c554e73ef8"},"id":"CrV8FmsgEuNX"},"source":["### ■総合問題8-1 教師あり学習の用語（2）\n","略"]},{"cell_type":"markdown","metadata":{"nbpresent":{"id":"0950100e-332d-4f7d-a865-47c554e73ef8"},"id":"ZPS_klrQEuNX"},"source":["### ■総合問題8-2 交差検証"]},{"cell_type":"markdown","metadata":{"id":"0Kc5BEBVEuNX"},"source":["乳がんデータセットを使って、予測モデル（ロジスティック回帰、SVM、決定木、k-NN、ランダムフォレスト、勾配ブースティング）を構築し、交差検証（5分割）により、どのモデルが一番良いか確認してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"snQ7O4DvEuNX"},"outputs":[],"source":["# 解答\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.tree import  DecisionTreeClassifier\n","from sklearn.neighbors import  KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","cancer = load_breast_cancer()\n","X_train, X_test, y_train, y_test = train_test_split(\n","    cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n","\n","models = {\n","    'KNN': KNeighborsClassifier(),\n","    'LogisticRegression': LogisticRegression(random_state=0),\n","    'DecisionTree': DecisionTreeClassifier(random_state=0),\n","    'SVM': LinearSVC(random_state=0),\n","    'RandomForest': RandomForestClassifier(random_state=0),\n","    'GradientBoost': GradientBoostingClassifier(random_state=0) \n","}\n","\n","scores = {}\n","for model_name, model in models.items():\n","    model.fit(X_train, y_train)\n","    scores[(model_name, 'train_score')] = model.score(X_train, y_train)\n","    scores[(model_name, 'test_score')] = model.score(X_test, y_test)\n","\n","pd.Series(scores).unstack()"]},{"cell_type":"markdown","metadata":{"id":"K51dyvmyEuNY"},"source":["今回は、勾配ブースティングがテストスコアがもっとも高く、0.958となりました。"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"nbpresent":{"slides":{"4ac36045-0899-4948-a386-6e758a2ecfb5":{"id":"4ac36045-0899-4948-a386-6e758a2ecfb5","prev":null,"regions":{"e61c6e12-b404-46aa-9d8d-e736102d1084":{"attrs":{"height":1,"width":1,"x":0,"y":0},"id":"e61c6e12-b404-46aa-9d8d-e736102d1084"}}}},"themes":{}},"colab":{"name":"week8/モデルの検証方法とチューニング方法_解答.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}